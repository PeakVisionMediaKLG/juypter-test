{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entscheidungsbäume (Decision Trees)\n",
    "## von Grund auf\n",
    "<br>\n",
    "<img width=500 height=300 class=\"imgright\" src=\"Images/Tree.png\" alt=\"restaurant\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei Entscheidungsbäumen handelt es sich um ein Beispiel von Entscheidungs-basierten Klassifikationsverfahren.\n",
    "Die Features eines Satzes von Samples werden in Abfragen überprüft und nach jeder Abfrage die Samples aufgeteilt in jeweils 2 Gruppen. Es handelt sich also somit um einen binären Baum, in dem die einzelnen Verzweigungen die Samples nach bestimmten Gesichtspunkten trennen, bis sich in den so entstehenden weiteren Knoten des Baumes nach Möglichkeit nur noch Samples jeweils einer der verschiedenen Klassen befinden. Dies wäre das Ziel der Klassifikation. Für unbekannte Testsamples könnten wir dann für die Klassifikation unseren Baum durchfahren und sehen, in welchen Endknoten (Blattknoten) die jeweiligen Samples enden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die aufzuteilenden Samples könnnen für die Features dabei sowohl kategorische Daten als auch kontinuierliche Daten enthalten also z.B. <br>für <b>Autos \"Dieselmotor\",\"4 Radantrieb\"... kategorisch</b><br>\n",
    "oder  z.B. für die <b>Körpergrösse 165cm, 176cm ... kontinuierlich.\n",
    "    <br></b>\n",
    "    Entsprechend heissen die Entscheidungsbäume dann ```kategorische Entscheidungsbäume``` oder ```kontinuierliche Entscheidungsbäume.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Knoten eines Entscheidungsbaumes haben eine bestimmte Terminologie. Das Ziel ist, in den Blattknoten nur jeweils einen Label zu haben.\n",
    "<br>\n",
    "<img width=800   src=\"Images/Terminologie Entscheidungsbäume.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nehmen wir als Beispiel Datenpunkte in einem zweidimensionalen Koordinatensystem mit den zwei Features x-Wert und y-Wert, die zu jeweils einer von zwei Kategorien gehören (rot und grün). Wir wollen hierfür einen kontinuierlichen Entscheidungsbaum erstellen. Zunächst unsere Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Koordinate: -5.00  Y-Koordinate:  0.50  Label: 0\n",
      "X-Koordinate: -4.50  Y-Koordinate: -1.50  Label: 0\n",
      "X-Koordinate: -4.20  Y-Koordinate:  3.30  Label: 0\n",
      "X-Koordinate: -3.00  Y-Koordinate: -2.00  Label: 0\n",
      "X-Koordinate: -1.50  Y-Koordinate: -0.80  Label: 1\n",
      "X-Koordinate: -1.20  Y-Koordinate:  1.30  Label: 1\n",
      "X-Koordinate: -0.50  Y-Koordinate:  0.50  Label: 1\n",
      "X-Koordinate:  0.00  Y-Koordinate:  0.00  Label: 1\n",
      "X-Koordinate:  0.30  Y-Koordinate:  1.40  Label: 1\n",
      "X-Koordinate:  0.50  Y-Koordinate: -0.50  Label: 1\n",
      "X-Koordinate:  1.20  Y-Koordinate:  0.10  Label: 1\n",
      "X-Koordinate:  2.00  Y-Koordinate:  1.70  Label: 1\n",
      "X-Koordinate:  1.80  Y-Koordinate: -1.20  Label: 1\n",
      "X-Koordinate:  0.20  Y-Koordinate:  3.20  Label: 0\n",
      "X-Koordinate:  2.20  Y-Koordinate:  3.80  Label: 0\n",
      "X-Koordinate:  4.00  Y-Koordinate:  0.20  Label: 0\n",
      "X-Koordinate:  3.20  Y-Koordinate: -1.90  Label: 0\n",
      "X-Koordinate:  5.00  Y-Koordinate: -1.00  Label: 0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa231a38bb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "L,labels=[],[]\n",
    "with open(\"Data/points.txt\",\"r\") as fh:\n",
    "    for line in fh:\n",
    "        x,y,label= line.rstrip().split(\",\")\n",
    "        L.append([float(x),float(y)])\n",
    "        labels.append (int(label))\n",
    "        print(f\"X-Koordinate: {float(x):5.2f}  Y-Koordinate: {float(y):5.2f}  Label: {int(label)}\")\n",
    "plt.figure(figsize=(6,6))\n",
    "L=np.array(L)\n",
    "plt.xlim(-6,6)\n",
    "plt.ylim(-6,6)\n",
    "colormap=np.array([\"red\",\"green\"])\n",
    "print(label)\n",
    "plt.scatter(L[:,0],L[:,1],color=colormap[labels],s=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Daten können wir nicht linear separieren.<br> Wie funktioniert nun unser Entscheidungsbaum?<br> Im Wurzelknoten haben wir alle 18 Punkte. Im ersten Knoten haben wir die Abfrage, ob der x-Wert grösser ist als -2. Falls dies der Fall ist, enthält der neue Knoten nur 4 rote Punkte, ist also rein und damit ein Blattknoten. Im anderen Fall haben wir noch 5 rote und 9 grüne Punkte im Knoten. Eine weitere Abfrage mit x<=3 spaltet diesen gemischten Knoten und es ergeben sich für den einen neuen Knoten bei \"ja\" 2 rote und 9 grüne Punkte. Im anderen Fall erhalten wir wieder einen Blattknoten mit 3 roten Punkten. Spalten wir unseren gemischten Knoten wieder auf mit y>=2 erhalten wir zwei Blattknoten mit 2 roten Punkte im Fall \"ja\" und 9 grünen Punkten bei \"nein\".<br>\n",
    "<img width=600 height=600 class=\"imgright\" src=\"Images/Entscheidungsbaum.png\" alt=\"restaurant\" />\n",
    "<br> Damit haben wir alle Punkte kategorisiert. In unserem Plot zeigen wir unsere 3 Entscheidungstrennlinien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa231943f70>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(-6,6)\n",
    "plt.ylim(-6,6)\n",
    "colormap=np.array([\"red\",\"green\"])\n",
    "print(label)\n",
    "plt.scatter(L[:,0],L[:,1],color=colormap[labels])\n",
    "plt.plot((-2,-2),(6,-6),c=\"black\")\n",
    "plt.plot((3,3),(6,-6),c=\"blue\")\n",
    "plt.plot((-6,6),(3,3),c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei komplexer Datensätzen kann es sein, dass wir nicht immer reine Blattknoten am Ende unseres Baumes erhalten. In diesem Fall machen wir eine Mehrheitsentscheidung und weisen den Punkten den Label zu, der am häufigsten im Knoten vorkommt. Warum machen wir dann nicht einfach weitere Abfragen und teilen die Knoten immer weiter auf bis wir reine Blattknoten erhalten? Dies würde im Extremfall dazu führen, dass jede Sample in einem eigenen Blattknoten liegt und würde einen extremen Fall von Overfitting darstellen. Wann wir unseren Entscheidungsbaum abbrechen, dazu später mehr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zweite Frage ist natürlich, wieso diese Methode dem maschinellen Lernen zugeordnet wird. Dazu muss man natürlich fragen: <b>Woher kommen die Bedingungen für unsere Abfragen? Diese muss die Maschine nämlich autonom gestalten. Aber wie kann sie das machen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn man unseren Wurzelknoten in verschiedener Weise aufspalten, bekommen wir natürlich unterschiedlich zusammengesetzte Tochterknoten. Nehmen wir als Bedingung x<=-2 erhalten wir die bekannte Aufteilung aus obigen Diagramm mit einem Knoten mit 4 roten Punkten und einem Knoten mit 5 roten und 9 grünen Punkten. Was wäre mit der Bedingung x>=0?<br>\n",
    "Wir hätten dann 6 grüne und 5 rote Punkte im \"Ja\" Knoten und 3 grüne und 4 rote Punkte im anderen Tochterknoten. Welche Aufteilung ist als besser zu beurteilen und führt zu einer schnelleren Klassifizierung? Natürlich die erste mit ihrem Ergebnis eines rein roten Blattknotens. Wie können wir dies quantifizieren? Hierzu gibt es eine Vielzahl von Verfahren, wir wollen damit die Aufteilung berechnen, die den größten Informationsgewinn bewirkt. Wie berechnen wir diesen Informationsgewinn?<br> Schauen wir uns den Wurzelknoten an, haben wir eine Wahrscheinlichkeit von .5 für jede der beiden Farben, wenn wir zufällig einen Punkt wählen. Diese Situation beschreibt eine maximale Heterogenität dieses Knotens. Ein häufiges Mass der Quantifizierung dieser Heterogenität stellt die Shannon Entropie dar, die von dem Informationswissenschaftler Claude Shannon bereits 1948 vorgestellt wurde. Berechnet wird sie mit $$Entropie =\\sum - p_i * log_2(p_i)$$ dabei ist $$p_i = Wahrscheinlichkeit\\ der\\ Klasse\\ i\\ im\\ Knoten$$. <br> Berechnet wird immer die Summe der Entropien der Tochterknoten je nach der durchgeführten Aufteilung. Diese wird minimiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In unserem <b>Wurzelknoten</b> wäre das also: $$-.5*-1+-.5*-1=0.5+0.5=1$$<br> Dies wäre die maximale Heterogenität oder Entropie, wie sie der Wurzelknoten ja zeigt.<br>\n",
    "Für unsere beiden möglichen Aufteilungen würden wir die Entropie unserer <b>Tochterknoten</b> jeweils addieren.<br>\n",
    "Im ersten Fall (x>=-2) ergäbe sich $$-1*0=0$$ <b>für den rein roten Knoten</b> und $$-4/14*log_2(4/14)+ -9/14*log_2(9/14)=.52+.41=.93$$ <b>für den gemischten Knoten.</b><br><br>\n",
    "Im zweiten Fall (x>=0) ergäbe sich $$-5/11*log_2(5/11)+ -6/11*log_2(6/11)=.52+.47=.99$$   <b>für den \"Ja\" Knoten</b> und <br>\n",
    "$$-4/7*log_2(4/7)+ -3/7*log_2(3/7)=.46+.52=.98$$ <b>für den \"Nein\" Knoten.</b><br>\n",
    "Sind wir am Informationsgewin durch die jeweilige Aufteilung interessiert, müssen wir berechnen, wie <b>die Gesamtentropie der beiden Knoten nach der Aufteilung gesunken ist,</b> je mehr desto mehr Informationsgewinn. Die Knoten können aber sehr unterschiedlich in ihrer Grösse sein, deshalb summieren wir nicht einfach die Einzelentropien der beiden Knoten sondern multiplizieren diese noch mit <b>der relativen Grösse der beiden Knoten</b> also<br><br> $$Anzahl\\ Elemente\\ im\\ jeweiligen Knoten/Anzahl\\ aller\\ Elemente\\ in\\ beiden\\ Knoten$$.<br> \n",
    "Das Ergebnis wäre im ersten Fall also: $$4/18*0 + 14/18*.93=.723$$<br>\n",
    "im zweiten Fall: $$11/18*.99 + 7/18*.98=.986$$<br>\n",
    "Die Entropie in ersten Fall ist also deutlich mehr gesunken und damit ist diese Aufteilung besser.<br> Die Aufgabe des Programms besteht also darin für alle möglichen Aufteilungen eines Knotens die zu finden, welche die Gesamtentropie der Tochterknoten am meisten sinken lässt im Vergleich zum Mutterknoten.<br> Haben wir nicht kontinuierliche Features, würde das Programm für alle Features dasjenige auswählen, welches eine Aufteilung des zu testenden Knotens mit dem grössten Abfall der Entropie der Tochterknoten ermöglicht. Bei kontinuierlichen Entscheidungsbäumen wäre es natürlich nicht möglich, für jede denkbare Abfrage und jedes Feature alle denkbaren Werte auszuprobieren. Hier testet das Programm für eine (grosse) Menge von (normalerweise gleichverteilten) Testwerten im Gesamtintervall des jeweiligen Features, welches der optimale Grenzwert (z.B. x<=1...) für die Abfrage für dieses Feature wäre.<br> Der Algorithmus eines Entscheidungsbaumes ist ein sogenannter \"greedy algorithm\", das heißt, an jedem Punkt wird die momentan beste Abfrage durchgeführt, es ist dann das jeweilige Feature verbraucht, es kann nicht mehr für weitere Test verwendet werden. Bei kategorischen Entscheidungsbäumen ist dies unmittelbar klar: Ein Knoten, der z.B. nach \"Art des Antriebs\" eines Autos z.B. in \"Diesel\" und \"Benziner\" aufgeteilt wird, übermittelt den Tochterknoten jeweils bezüglich dieses Features reine Werte (nicht aber natürlich bezüglich der anderen Features). Eine erneute Abfrage nach diesem Feature wäre also sinnlos. Bei kontinuierlichen Entscheidungsbäumen wird, wie oben erwähnt, ebenfalls der beste Grenzwert für die Aufteilung des Knotens berechnet. Eine erneute Aufteilung mit strengeren Grenzwerten wäre aber möglich (s.unteres Beispiel mit sklearn). Daß so immer die beste Aufteilung erreicht wird, ist nicht garantiert. Meist ist aber auch unter diesen Bedingungen, die eine schnelle Berechnung ermöglichen, eine sehr effektive Implementierung eines Entscheidungsbaums möglich.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir zeigen nun einen einfachen kategorischen Entscheidungsbaum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem Beispiel könnten wir so Tiere in 2 Klassen , nämlich Säugetiere und Fische als Labels (class_type=1 für Säugetiere, class_type=4 für Fische) aufteilen.\n",
    "Die Features wären Boolsche Daten, also entweder True oder False (0,1).<br> \n",
    "Die einzelnen Features:<br>\n",
    "hat es Zähne?<br>ist es ein Haustier?<br>hat es einen Schwanz?<br>ist es ein Raubtier?<br>\n",
    "Wir lesen dazu das UCI Zoo Data Set ein, welches 102 Tiere mit ihren Eigenschaften (17) enthält. Hier ein Ausschnitt mit den ersten 10 Tieren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_name</th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airbone</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animal_name</td>\n",
       "      <td>hair</td>\n",
       "      <td>feathers</td>\n",
       "      <td>eggs</td>\n",
       "      <td>milk</td>\n",
       "      <td>airborne</td>\n",
       "      <td>aquatic</td>\n",
       "      <td>predator</td>\n",
       "      <td>toothed</td>\n",
       "      <td>backbone</td>\n",
       "      <td>breathes</td>\n",
       "      <td>venomous</td>\n",
       "      <td>fins</td>\n",
       "      <td>legs</td>\n",
       "      <td>tail</td>\n",
       "      <td>domestic</td>\n",
       "      <td>catsize</td>\n",
       "      <td>class_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>antelope</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>buffalo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>calf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>carp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>catfish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   animal_name  hair  feathers  eggs  milk   airbone  aquatic  predator  \\\n",
       "0  animal_name  hair  feathers  eggs  milk  airborne  aquatic  predator   \n",
       "1     aardvark     1         0     0     1         0        0         1   \n",
       "2     antelope     1         0     0     1         0        0         0   \n",
       "3         bass     0         0     1     0         0        1         1   \n",
       "4         bear     1         0     0     1         0        0         1   \n",
       "5         boar     1         0     0     1         0        0         1   \n",
       "6      buffalo     1         0     0     1         0        0         0   \n",
       "7         calf     1         0     0     1         0        0         0   \n",
       "8         carp     0         0     1     0         0        1         0   \n",
       "9      catfish     0         0     1     0         0        1         1   \n",
       "\n",
       "   toothed  backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \\\n",
       "0  toothed  backbone  breathes  venomous  fins  legs  tail  domestic  catsize   \n",
       "1        1         1         1         0     0     4     0         0        1   \n",
       "2        1         1         1         0     0     4     1         0        1   \n",
       "3        1         1         0         0     1     0     1         0        0   \n",
       "4        1         1         1         0     0     4     0         0        1   \n",
       "5        1         1         1         0     0     4     1         0        1   \n",
       "6        1         1         1         0     0     4     1         0        1   \n",
       "7        1         1         1         0     0     4     1         1        1   \n",
       "8        1         1         0         0     1     0     1         1        0   \n",
       "9        1         1         0         0     1     0     1         0        0   \n",
       "\n",
       "        class  \n",
       "0  class_type  \n",
       "1           1  \n",
       "2           1  \n",
       "3           4  \n",
       "4           1  \n",
       "5           1  \n",
       "6           1  \n",
       "7           1  \n",
       "8           4  \n",
       "9           4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = pd.read_csv('Data/zoo.csv',names=['animal_name','hair','feathers','eggs','milk',\n",
    "                                                   'airbone','aquatic','predator','toothed','backbone',\n",
    "                                                  'breathes','venomous','fins','legs','tail','domestic','catsize','class',])\n",
    "dataset[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen uns auf die Tiere mit der Klasse 1 für Säugetiere und 4 für Fische beschränken und auch nur die genannten Features \"toothed\", \"domestic\", \"tail\" und \"predator\" verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Säugetiere: 41\n",
      "Fische: 13\n",
      "   domestic toothed tail predator class\n",
      "1         0       1    0        1     1\n",
      "2         0       1    1        0     1\n",
      "3         0       1    1        1     4\n",
      "4         0       1    0        1     1\n",
      "5         0       1    1        1     1\n",
      "6         0       1    1        0     1\n",
      "7         1       1    1        0     1\n",
      "8         1       1    1        0     4\n",
      "9         0       1    1        1     4\n",
      "10        1       1    0        0     1\n",
      "11        0       1    1        1     1\n",
      "13        0       1    1        1     4\n",
      "18        0       1    1        0     1\n",
      "19        0       1    1        1     4\n",
      "20        0       1    1        1     1\n",
      "23        0       1    1        0     1\n",
      "28        0       1    1        0     1\n",
      "29        0       1    1        0     1\n",
      "30        1       1    0        1     1\n",
      "32        1       1    1        0     1\n",
      "33        0       1    0        0     1\n",
      "35        0       1    1        0     4\n",
      "36        1       1    1        0     1\n",
      "37        0       1    1        0     1\n",
      "39        0       1    1        1     4\n",
      "45        0       1    1        1     1\n",
      "46        0       1    1        1     1\n",
      "48        0       1    1        1     1\n",
      "49        0       1    1        1     1\n",
      "50        0       1    1        1     1\n",
      "51        0       1    1        1     1\n",
      "55        0       1    1        1     1\n",
      "56        0       1    1        0     1\n",
      "61        0       1    1        1     4\n",
      "62        0       1    1        1     4\n",
      "64        0       0    1        1     1\n",
      "65        0       1    1        1     1\n",
      "66        1       1    1        0     1\n",
      "67        0       1    1        1     1\n",
      "68        0       1    1        1     1\n",
      "69        1       1    1        1     1\n",
      "70        0       1    1        1     1\n",
      "71        1       1    1        0     1\n",
      "74        0       1    1        0     4\n",
      "75        0       1    0        1     1\n",
      "76        0       1    1        1     1\n",
      "83        0       1    1        0     4\n",
      "85        0       1    1        0     1\n",
      "87        0       1    1        1     4\n",
      "93        0       1    1        1     4\n",
      "94        0       1    1        0     1\n",
      "95        0       1    1        0     1\n",
      "97        0       1    1        0     1\n",
      "99        0       1    1        1     1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d0 = dataset[['domestic', 'toothed', 'tail','predator','class']]\n",
    "d_1 = d0[d0['class'] == '1']\n",
    "d_4 = d0[d0['class'] == '4']\n",
    "print(f\"Säugetiere: {d_1.shape[0]}\")\n",
    "print(f\"Fische: {d_4.shape[0]}\")\n",
    "\n",
    "d_to_test = d0[np.logical_or(d0['class'] == '1',d0['class'] == \"4\")] #alle Säugetiere und Reptilien\n",
    "print(d_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lassen wir uns jetzt ausgeben, welche Zusammensetzung die ersten Zwischenknoten hätten, wenn wir jeweils für <br>hat es Zähne?<br>hat es einen Schwanz?<br>hat es Beine?<br>ist es ein Raubtier? <br>unseren Datensatz aufteilen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " für domestic True haben wir 8 Säugetiere und 1 Fische Knoten 1 \n",
      " für domestic False haben wir 33 Säugetiere und 12 Fische Knoten 2 \n",
      "\n",
      " für toothed True haben wir 40 Säugetiere und 13 Fische Knoten 1 \n",
      " für toothed False haben wir 1 Säugetiere und 0 Fische Knoten 2 \n",
      "\n",
      " für tail True haben wir 35 Säugetiere und 13 Fische Knoten 1 \n",
      " für tail False haben wir 6 Säugetiere und 0 Fische Knoten 2 \n",
      "\n",
      " für predator True haben wir 22 Säugetiere und 9 Fische Knoten 1 \n",
      " für predator False haben wir 19 Säugetiere und 4 Fische Knoten 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "features=['domestic', 'toothed', 'tail','predator']\n",
    "for feature in features:\n",
    "    node_True_1=d_to_test[np.logical_and(d_to_test[\"class\"]==\"1\",d_to_test[feature]==\"1\")]\n",
    "    node_True_4=d_to_test[np.logical_and(d_to_test[\"class\"]==\"4\",d_to_test[feature]==\"1\")]\n",
    "    node_False_1=d_to_test[np.logical_and(d_to_test[\"class\"]==\"1\",d_to_test[feature]==\"0\")]\n",
    "    node_False_4=d_to_test[np.logical_and(d_to_test[\"class\"]==\"4\",d_to_test[feature]==\"0\")]\n",
    "    print(f\" für {feature} True haben wir {len(node_True_1)} Säugetiere und {len(node_True_4)} Fische Knoten 1 \")\n",
    "    print(f\" für {feature} False haben wir {len(node_False_1)} Säugetiere und {len(node_False_4)} Fische Knoten 2 \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen wir nun die Shannon-Entropie einiger Knoten.<br><br>\n",
    "Ein Beispiel für den Test auf \"domestic\".<br>\n",
    "In Knoten 1 haben wir:<br><br>\n",
    "$p_{säugetier} = 8/9$ &emsp;&emsp; $Entropie_{säugetier} = 8/9 * log_2(8/9) = - 0.151$<br><br> \n",
    "$p_{fisch}= 1/9$ &emsp;&emsp; $Entropie_{fisch} = 1/9 * log_2(1/9) = - 0.352$<br><br> \n",
    "$Gesamt_{Knoten1} = 0.503$\n",
    "\n",
    "<br><br>In Knoten 2 haben wir:<br><br>\n",
    "$p_{säugetier} = 33/45$ &emsp;&emsp; $Entropie_{säugetier} = 33/45 * log_2(33/45) = - 0.328$<br><br> \n",
    "$p_{fisch}= 12/45$ &emsp;&emsp; $Entropie_{fisch} = 12/45 * log_2(12/45) = - 0.509$<br><br> \n",
    "$Gesamt_{Knoten1} = 0.837$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können auf diese Weise den \"Reinheitswert\" für jeden Knoten als Shannon-Entropie messen, wobei ein vollständig reiner Knoten einen Wert von 1 hat.<br>\n",
    "Knoten2 für \"tail\" wäre ein solcher Knoten mit Shannon-Entropie 1.\n",
    "Wie wäre die Entropie für unseren Wurzelknoten?<br><br>\n",
    "$$-(41/54*log_2(41/54)+13/54*log_2(13/54)) = -(-0.302 + -0.495) = 0.797$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Gesamtentropie nach der Aufteilung eines Knotens in zwei Einzelknoten berechnen wir mit der Summe aus <br><br>\n",
    "$$ p_{feature\\ in\\ Knoten1} * GesamtEntropie_{Knoten1} + p_{feature\\ in\\ Knoten2} * GesamtEntropie_{Knoten2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machen wir dies für unsere vier möglichen Aufteilungen erhalten wir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " für domestic True haben wir 8 Säugetiere und 1 Fische Knoten 1 \n",
      " für domestic False haben wir 33 Säugetiere und 12 Fische Knoten 2 \n",
      " Gesamtentropie für diese Aufteilung: 0.781\n",
      "\n",
      " für toothed True haben wir 40 Säugetiere und 13 Fische Knoten 1 \n",
      " für toothed False haben wir 1 Säugetiere und 0 Fische Knoten 2 \n",
      " Gesamtentropie für diese Aufteilung: 0.789\n",
      "\n",
      " für tail True haben wir 35 Säugetiere und 13 Fische Knoten 1 \n",
      " für tail False haben wir 6 Säugetiere und 0 Fische Knoten 2 \n",
      " Gesamtentropie für diese Aufteilung: 0.749\n",
      "\n",
      " für predator True haben wir 22 Säugetiere und 9 Fische Knoten 1 \n",
      " für predator False haben wir 19 Säugetiere und 4 Fische Knoten 2 \n",
      " Gesamtentropie für diese Aufteilung: 0.783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features=['domestic', 'toothed', 'tail','predator']\n",
    "for feature in features:\n",
    "    Gesamt=len(d_to_test)\n",
    "    node_True_1=d_to_test[np.logical_and(d_to_test[\"class\"]==\"1\",d_to_test[feature]==\"1\")]    \n",
    "    node_True_4=d_to_test[np.logical_and(d_to_test[\"class\"]==\"4\",d_to_test[feature]==\"1\")]\n",
    "    node_False_1=d_to_test[np.logical_and(d_to_test[\"class\"]==\"1\",d_to_test[feature]==\"0\")]\n",
    "    node_False_4=d_to_test[np.logical_and(d_to_test[\"class\"]==\"4\",d_to_test[feature]==\"0\")]        \n",
    "    print(f\" für {feature} True haben wir {len(node_True_1)} Säugetiere und {len(node_True_4)} Fische Knoten 1 \")\n",
    "    print(f\" für {feature} False haben wir {len(node_False_1)} Säugetiere und {len(node_False_4)} Fische Knoten 2 \")\n",
    "    p1=(len(node_True_1)+len(node_True_4))/Gesamt\n",
    "    p2=(len(node_False_1)+len(node_False_4))/Gesamt    \n",
    "    pT1=len(node_True_1)/(len(node_True_1)+len(node_True_4))    \n",
    "    pT4=len(node_True_4)/(len(node_True_1)+len(node_True_4))    \n",
    "    pF1=len(node_False_1)/(len(node_False_1)+len(node_False_4))\n",
    "    pF4=len(node_False_4)/(len(node_False_1)+len(node_False_4))\n",
    "    eT1=0 if pT1==0 else pT1*np.log2(pT1)\n",
    "    eT4=0 if pT4==0 else pT4*np.log2(pT4)\n",
    "    eF1=0 if pF1==0 else pF1*np.log2(pF1)\n",
    "    eF4=0 if pF4==0 else pF4*np.log2(pF4)    \n",
    "    Gesamt_e=p1*-(eT1+eT4)+p2*-(eF1+eF4)\n",
    "    print(f\" Gesamtentropie für diese Aufteilung: {round(Gesamt_e,3)}\\n\")\n",
    "    #print(f\"Knoten1 enthält: {pd.concat([node_True_1,node_True_4])}\")\n",
    "    #print(f\"Knoten2 enthält: {pd.concat([node_False_1,node_False_4])}\")\n",
    "    if feature==\"tail\":\n",
    "        d_neu=pd.concat([node_True_1,node_True_4])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können jetzt sehen, dass für jede Aufteilung die Gesamtentropie der beiden neuen Knoten im Vergleich zum Wurzelknoten (0.797) sinkt. Am stärksten ist der Rückgang für das Merkmal \"tail\".<br>\n",
    "Wir würden jetzt diese Aufteilung vornehmen. Das Merkmal \"tail\" können wir dann für weitere Aufteilungen weglassen. Es verbleiben dann nur noch 3 Merkmale. Desweiteren ist für das Merkmal \"tail\" == False die Zusammensetzung des Knotens rein mit 6 Säugetieren und keinem Fisch. Dieser Knoten würde dann als Blattknoten Säugetier bekommen. Unsere Aufteilung sieht nun so aus:\n",
    "<br><br><img width=900   src=\"Images/Entscheidungsbaum1.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir machen nun weiter mit dem linken Knoten. Es stehen uns 3 Möglichkeiten der Aufteilung zur Verfügung:<br>\n",
    "    \"toothed\",\"domestic\" und \"predator\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " für domestic True haben wir 6 Säugetiere und 1 Fische Knoten 1 \n",
      " für domestic False haben wir 29 Säugetiere und 12 Fische Knoten 2 \n",
      " Gesamtentropie für diese Aufteilung: 0.831\n",
      "\n",
      " für toothed True haben wir 34 Säugetiere und 13 Fische Knoten 1 \n",
      " für toothed False haben wir 1 Säugetiere und 0 Fische Knoten 2 \n",
      " Gesamtentropie für diese Aufteilung: 0.833\n",
      "\n",
      " für predator True haben wir 18 Säugetiere und 9 Fische Knoten 1 \n",
      " für predator False haben wir 17 Säugetiere und 4 Fische Knoten 2 \n",
      " Gesamtentropie für diese Aufteilung: 0.824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_to_test=d_neu\n",
    "features=['domestic', 'toothed', 'predator']\n",
    "for feature in features:\n",
    "    Gesamt=len(d_to_test)\n",
    "    node_True_1=d_to_test[np.logical_and(d_to_test[\"class\"]==\"1\",d_to_test[feature]==\"1\")]    \n",
    "    node_True_4=d_to_test[np.logical_and(d_to_test[\"class\"]==\"4\",d_to_test[feature]==\"1\")]\n",
    "    node_False_1=d_to_test[np.logical_and(d_to_test[\"class\"]==\"1\",d_to_test[feature]==\"0\")]\n",
    "    node_False_4=d_to_test[np.logical_and(d_to_test[\"class\"]==\"4\",d_to_test[feature]==\"0\")]        \n",
    "    print(f\" für {feature} True haben wir {len(node_True_1)} Säugetiere und {len(node_True_4)} Fische Knoten 1 \")\n",
    "    print(f\" für {feature} False haben wir {len(node_False_1)} Säugetiere und {len(node_False_4)} Fische Knoten 2 \")\n",
    "    p1=(len(node_True_1)+len(node_True_4))/Gesamt\n",
    "    p2=(len(node_False_1)+len(node_False_4))/Gesamt    \n",
    "    pT1=len(node_True_1)/(len(node_True_1)+len(node_True_4))    \n",
    "    pT4=len(node_True_4)/(len(node_True_1)+len(node_True_4))    \n",
    "    pF1=len(node_False_1)/(len(node_False_1)+len(node_False_4))\n",
    "    pF4=len(node_False_4)/(len(node_False_1)+len(node_False_4))\n",
    "    eT1=0 if pT1==0 else pT1*np.log2(pT1)\n",
    "    eT4=0 if pT4==0 else pT4*np.log2(pT4)\n",
    "    eF1=0 if pF1==0 else pF1*np.log2(pF1)\n",
    "    eF4=0 if pF4==0 else pF4*np.log2(pF4)    \n",
    "    Gesamt_e=p1*-(eT1+eT4)+p2*-(eF1+eF4)\n",
    "    print(f\" Gesamtentropie für diese Aufteilung: {round(Gesamt_e,3)}\\n\")\n",
    "    #print(f\"Knoten1 enthält: {pd.concat([node_True_1,node_True_4])}\")\n",
    "    #print(f\"Knoten2 enthält: {pd.concat([node_False_1,node_False_4])}\")\n",
    "    if feature==\"predator\":\n",
    "        d_neu_true=pd.concat([node_True_1,node_True_4])\n",
    "        d_neu_false=pd.concat([node_False_1,node_False_4])\n",
    "        #print(d_neu_true)\n",
    "        #print(d_neu_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Knoten links hat eine Ausgangsentropie von: <br>\n",
    "-(35/48* np.log2(35/48)+13/48* np.log2(13/48)) = <b>0.843<br>\n",
    "    </b> Die Aufteilung nach \"predator\" erlaubt den grössten Rückgang der Entropie von 0.019 . Wir werden sie nun durchführen.<br><br><img width=600   src=\"Images/Entscheidungsbaum2.png\"  />\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So würden wir weitermachen bis zum Abbruch des Verfahrens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Wann brechen wir die Aufsplittung der Knoten ab? \n",
    "1. Der Knoten ist pur bezüglich der Label. Wir haben also einen Blattknoten.<br>\n",
    "2. Es sind alle Features verarbeitet worden. Ein Splitten ist also nicht mehr möglich, da das Kriterium fehlt.<br>\n",
    "3. Es entstehen leere Tochterknoten.</b><br>\n",
    "Für die weiteren Schritte wollen wir jetzt aus der sklearn Bibliothek das Modul tree zur Erstellung von Entscheidungsbäumen benutzen. Wir beschränken zunächst unseren Baum wieder auf Fische und Säuger und verwenden nur unsere Merkmale wie vorher. Wir teilen unsere Daten in 34 Trainingsdatensätze und 14 Testdatensätze auf. Man sieht, dass die Accuracy für die Testdaten nur bei ca. 75% liegt, was bei unserem sehr kleinen Datensatz nicht verwunderlich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  85.0 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import the DecisionTreeClassifier model.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import  graphviz\n",
    "import numpy as np\n",
    "#Import the DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Import the Zoo Dataset\n",
    "\"\"\"\n",
    "\n",
    "#Import the dataset \n",
    "dataset = pd.read_csv('Data/zoo.csv')\n",
    "\n",
    "cols_to_keep=['domestic', 'toothed', 'tail','predator','class_type']\n",
    "dataset=dataset.loc[:, cols_to_keep]\n",
    "säuger =  dataset['class_type']==1\n",
    "fisch =  dataset[\"class_type\"]==4\n",
    "dataset1=dataset[säuger]\n",
    "dataset2=dataset[fisch]\n",
    "dataset=pd.concat([dataset1,dataset2])\n",
    "#print(dataset,len(dataset))\n",
    "index = dataset.index\n",
    "dataset = shuffle(dataset)\n",
    "dataset.index = index\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Split the data into a training and a testing set\n",
    "\"\"\"\n",
    "\n",
    "#train_features = dataset.iloc[:34,:-1]\n",
    "test_features = dataset.iloc[34:,:-1]\n",
    "train_features= dataset.iloc[:,:-1]\n",
    "train_targets= dataset.iloc[:,-1]\n",
    "#train_targets = dataset.iloc[:34,-1]\n",
    "test_targets = dataset.iloc[34:,-1]\n",
    "#print(test_targets,type(test_targets))\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Train the model\n",
    "\"\"\"\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy').fit(train_features,train_targets)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Predict the classes of new, unseen data\n",
    "\"\"\"\n",
    "prediction = tree.predict(test_features)\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Check the accuracy\n",
    "\"\"\"\n",
    "\n",
    "print(\"The prediction accuracy is: \",tree.score(test_features,test_targets)*100,\"%\")\n",
    "#plot_tree(tree)\n",
    "plt.rcParams[\"figure.figsize\"]=30,30\n",
    "\n",
    "#plt.show()\n",
    "classes=[\"Säugetier\",\"Vogel\",\"Reptilien\",\"Fische\",\"Amphibien\",\"Gliedertiere\",\"Wirbellose\"]\n",
    "#dot_data=export_graphviz(tree, out_file=None)\n",
    "dot_data = export_graphviz(tree, out_file=None, feature_names=test_features.columns.values, class_names=classes, filled=True, rounded=True,special_characters=True)  \n",
    "#graph = graphviz.Source(dot_data)\n",
    "#graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><img width=900   src=\"Images/tree_animals.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen nun das komplette UCI Zoo Data Set mit 101 Tieren auswerten. Es enthält die Klassen:<br>\n",
    "1-> Säugetier<br>\n",
    "2-> Vogel<br>\n",
    "3-> Reptilien<br>\n",
    "4-> Fische<br>\n",
    "5-> Amphibien<br>\n",
    "6-> Gliedertiere<br>\n",
    "7-> Wirbellose<br>\n",
    "Wir spalten die Datensätze in 80 Trainingsdatensätze und 21 Testdatensätze.\n",
    "Die Accuracy für unsere Testdaten liegt zwischne 80 und 100% je nach dem zufälligen Aufteilen der Datensätze in Training- und Testdaten. Dies ist für eine so kleinen Datensatz mit sovielen Feature wirklich erstaunlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  90.48 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import the DecisionTreeClassifier model.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import  graphviz\n",
    "import numpy as np\n",
    "#Import the DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Import the Zoo Dataset\n",
    "\"\"\"\n",
    "\n",
    "#Import the dataset \n",
    "dataset = pd.read_csv('Data/zoo.csv')\n",
    "\n",
    "dataset=dataset.drop('animal_name',axis=1)\n",
    "dataset=shuffle(dataset)\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Split the data into a training and a testing set\n",
    "\"\"\"\n",
    "\n",
    "train_features = dataset.iloc[:80,:-1]\n",
    "test_features = dataset.iloc[80:,:-1]\n",
    "train_targets = dataset.iloc[:80,-1]\n",
    "test_targets = dataset.iloc[80:,-1]\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Train the model\n",
    "\"\"\"\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy').fit(train_features,train_targets)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Predict the classes of new, unseen data\n",
    "\"\"\"\n",
    "prediction = tree.predict(test_features)\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Check the accuracy\n",
    "\"\"\"\n",
    "\n",
    "print(\"The prediction accuracy is: \",round(tree.score(test_features,test_targets)*100,2),\"%\")\n",
    "#plot_tree(tree)\n",
    "#plt.rcParams[\"figure.figsize\"]=30,30\n",
    "\n",
    "#plt.show()\n",
    "classes=[\"Säugetier\",\"Vögel\",\"Reptilien\",\"Fische\",\"Amphibien\",\"Gliedertiere\",\"Wirbellose\"]\n",
    "dot_data=export_graphviz(tree, out_file=None)\n",
    "dot_data = export_graphviz(tree, out_file=None, feature_names=test_features.columns.values,class_names=classes, filled=True, rounded=True,\n",
    "                          special_characters=True,leaves_parallel=False )  \n",
    "#graph = graphviz.Source(dot_data)\n",
    "#graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><img width=900   src=\"Images/KompletterBaum.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusammenfassend sind Entscheidungsbäume sehr effektive ML-Algorithmen. Sie können sowohl für kategorische Daten als auch für kontinuierliche Daten angewendet werden. Eine Datenpräparation, wie sie von vielen anderen ML-Algorithmen essentiell benötigt wird, ist hier meistens nicht erforderlich. Sie sind sehr robust bezüglich des möglichen Zusammenhangs der einzelnen Features, es wird keine lineare Abhängigkeit vorausgesetzt. Es lassen sich die Zusammenhänge zwischen den Features optisch in der Baumform gut erkennen. \n",
    "Sie haben aber natürlich auch Nachteile:\n",
    "Sie neigen zum Overfitting, vor allem, wenn man die Baumtiefe nicht beschränkt und mögliche Optimierungen (auf die wir in diesem Rahmen nicht eingehen können) nicht benutzt werden. Kleine Veränderungen im Datensatz können zu völlig anderen Bäumen führen. <b>Man kann diesen Nachteil ausgleichen, indem man das Konzept erweitert auf Zufallswälder (Random Forests), indem man viele verschiedene Entscheidungsbäume erzeugt und dann daraus einen optimalen Gesamtbaum generiert.</b> Grosse Bäume können sehr unübersichtlich und schwer zu interpretieren werden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "## Zufallswälder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei Random Forests oder Zufallswäldern handelt es sich um sog. Ensemble-Lernmethoden. Dies bedeutet, daß verschiedene Lerntechniken (hier Entscheidungsbäume, deshalb Forests) kombiniert werden oder bei einer Lerntechnik verschiedene Auswahlen von Datensatzgruppen bearbeitet werden, und dann eine Zusammenfassung der Einzelergebnisse das letztendliche Ergebnis darstellt. Gerade Verfahren wie Entscheidungsbäume, die sich auch bei kleinen Abweichungen der Ursprungsbedingungen sehr verändern können, wird durch mehrfaches Durchführen des Algorithmus mit leicht unterschiedlichen Datensätzen und Mitteln des Ergebnisses eine deutlich höhrere Leistungsfähigkeit erreicht. Wir erhalten die unterschiedlichen Ergebnisse, indem wir zufällig ausgewählte Batches oder Teilmengen der Daten in einzelnen Entscheidungsbäumen auswerten (Bootstrapping). Diese Ergebnisse fassen wir dann zusammen (Bagging), zum Beispiel könnte für eine Sample der Label letztendlich vorhergesagt werden, der sich am häufigsten in den Einzelentscheiduungsbäumen ergab (Majority Voting). <br>\n",
    "Während in anderen Ensemble-Verfahren oft nicht unmittelbar klar ist, wie die zusammengefasste Lösung am Ende ensteht, ist dies für Random Forests einfach, da man sich alle einzelnen Entscheidungsbäume anschauen kann. Wir machen jetzt ein Beispiel mit sklearn und der Datei für maschinelles Lernen \"wine.data\" von der Universität von Kalifornien Irvine. Diese enthält Angaben (13 Features) über 178 Weine. Diese werden in  3 Kategorien aufgeteilt. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0            1    14.23        1.71  2.43               15.6        127   \n",
      "1            1    13.20        1.78  2.14               11.2        100   \n",
      "2            1    13.16        2.36  2.67               18.6        101   \n",
      "3            1    14.37        1.95  2.50               16.8        113   \n",
      "4            1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "Länge des Datenstes 178\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_wine = pd.read_csv('Data/wine.data', header=0)\n",
    "#df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',header=None)\n",
    "                      \n",
    "#df_wine.to_csv('wine.data', index=False)\n",
    "\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "                   'Proline']\n",
    "\n",
    "print(df_wine[:5])\n",
    "df_wine_np=np.array(df_wine)\n",
    "print(df_wine_np[:,0])\n",
    "print(f\"Länge des Datenstes {len(df_wine_np)}\")\n",
    "# df_wine = pd.read_csv('wine.data', header=None)\n",
    "\n",
    "# drop 1 class\n",
    "df_wine = df_wine[df_wine['Class label'] != 1]\n",
    "\n",
    "y = df_wine['Class label'].values-2 #spart Label encoder\n",
    "\n",
    "\n",
    "X = df_wine[['Alcohol', 'Malic acid']].values\n",
    "#print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "            train_test_split(X, y, \n",
    "                             test_size=0.3, \n",
    "                             random_state=1,\n",
    "                             stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.tree import plot_tree\n",
    "#objekte bauen\n",
    "tree = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=4,\n",
    "                              random_state=3)\n",
    "\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=tree, #5000 verschiedene Entscheidungsbäume auswerten mit Bootsstrapping\n",
    "                        n_estimators=5000, \n",
    "                        max_samples=1.0, \n",
    "                        max_features=1.0, \n",
    "                        bootstrap=True, \n",
    "                        bootstrap_features=False, \n",
    "                        n_jobs=1, \n",
    "                        random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train/test accuracies 0.916/0.778\n",
      "Bagging train/test accuracies 0.988/0.861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree = tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "\n",
    "tree_train = accuracy_score(y_train, y_train_pred)\n",
    "tree_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f'\n",
    "      % (tree_train, tree_test))\n",
    "\n",
    "bag = bag.fit(X_train, y_train)\n",
    "y_train_pred = bag.predict(X_train)\n",
    "y_test_pred = bag.predict(X_test)\n",
    "\n",
    "bag_train = accuracy_score(y_train, y_train_pred) \n",
    "bag_test = accuracy_score(y_test, y_test_pred) \n",
    "print('Bagging train/test accuracies %.3f/%.3f'\n",
    "      % (bag_train, bag_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben jetzt mit dem sogenannten Bagging einen Konsensbaum aus 1000 einzelnen Entscheidungsbäumen mit verschiedenen Batches produziert und zeigen jetzt den Unterschied zwischen den Entscheidungsgrenzen für einem einzelnen Entscheidungsbaum und den Konsensbaum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_min = X_train[:, 0].min() - 1\n",
    "x_max = X_train[:, 0].max() + 1\n",
    "y_min = X_train[:, 1].min() - 1\n",
    "y_max = X_train[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(nrows=1, ncols=2, \n",
    "                        sharex='col', \n",
    "                        sharey='row', \n",
    "                        figsize=(12, 8))\n",
    "\n",
    "\n",
    "for idx, clf, tt in zip([0, 1],\n",
    "                        [tree, bag],\n",
    "                        ['Decision tree', 'Bagging']):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr[idx].contourf(xx, yy, Z, alpha=0.3)\n",
    "    axarr[idx].scatter(X_train[y_train == 0, 0],\n",
    "                       X_train[y_train == 0, 1],\n",
    "                       c='blue', marker='^')\n",
    "\n",
    "    axarr[idx].scatter(X_train[y_train == 1, 0],\n",
    "                       X_train[y_train == 1, 1],\n",
    "                       c='green', marker='o')\n",
    "\n",
    "    axarr[idx].set_title(tt)\n",
    "\n",
    "axarr[0].set_ylabel('Alcohol', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.text(0, -0.1,\n",
    "         s='Malic Acid',\n",
    "         ha='center',\n",
    "         va='center',\n",
    "         fontsize=12,\n",
    "         transform=axarr[1].transAxes)\n",
    "\n",
    "#plt.savefig('images/07_08.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei unserem einfachen Beispiel gewinnen wir durch Bagging deutlich an Accuracy. Wir sehen auch, daß ein Hinweis für Overfitting vorliegt.<b><br> Decision tree train/test accuracies 0.916/0.778<br>\n",
    "Bagging train/test accuracies 0.988/0.861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
