{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Klassifikator mit Scikit\n",
    "\n",
    "<img width=\"60%\" class=\"imgright\" src=\"../images/classifiers_off_the_rack.webp\" srcset=\"../images/classifiers_off_the_rack_500w.webp 500w,../images/classifiers_off_the_rack_400w.webp 400w,../images/classifiers_off_the_rack_350w.webp 350w,../images/classifiers_off_the_rack_300w.webp 300w\" alt=\"off the rack classifiers\" />\n",
    "\n",
    "Im vorigen Kapitel haben wir einen Naive Bayes Klassifikator von Grund auf geschrieben. In diesem Kapitel zeigen wir, wie Sie den bereits fertigen Naive Bayes Klassifikator \"von der Stange\" zur Verfügung.\n",
    "\n",
    "In unserem ersten Beispiel verwenden wir das Iris-Dataset um den Klassifikator zu trainieren und zu testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       0.94      0.94      0.94        50\n",
      "          2       0.94      0.94      0.94        50\n",
      "\n",
      "avg / total       0.96      0.96      0.96       150\n",
      "\n",
      "Konfusionsmatrix:\n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Iris-Datasets laden\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# Naive Bayes Model mit den Daten füttern\n",
    "model = GaussianNB()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "\n",
    "# Vorhersagen treffen\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "#  Zusammenfassung\n",
    "print(\"Report:\\n\", metrics.classification_report(expected, predicted))\n",
    "print(\"Konfusionsmatrix:\\n\", metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir verwenden nun einmal die Personen-Daten aus dem vorigen Kapitel um einen weiteren Klassifikator zu trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prepare_person_dataset(fname):\n",
    "    genders = [\"male\", \"female\"]\n",
    "    persons = []\n",
    "    with open(fname) as fh:\n",
    "        for line in fh:\n",
    "            persons.append(line.strip().split())\n",
    "            \n",
    "    dataset = [] #Größe, Gewicht und Geschlecht\n",
    "    \n",
    "    for person in persons:\n",
    "        height_weight = (float(person[2]), float(person[3]))\n",
    "        dataset.append( (height_weight, person[4])) \n",
    "    return dataset\n",
    "\n",
    "learnset = prepare_person_dataset(\"data/person_data.txt\")\n",
    "testset = prepare_person_dataset(\"data/person_data_testset.txt\")\n",
    "#print(learnset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     female       0.68      0.80      0.73        50\n",
      "       male       0.76      0.62      0.68        50\n",
      "\n",
      "avg / total       0.72      0.71      0.71       100\n",
      "\n",
      "Konfusionsmatrix:\n",
      " [[40 10]\n",
      " [19 31]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "w, l = zip(*learnset)\n",
    "w = np.array(w)\n",
    "l = np.array(l)\n",
    "\n",
    "model.fit(w, l)\n",
    "#print(model)\n",
    "\n",
    "w, l = zip(*testset)\n",
    "w = np.array(w)\n",
    "l = np.array(l)\n",
    "predicted = model.predict(w)\n",
    "\n",
    "# Zusammenfassung\n",
    "print(\"Report:\\n\", metrics.classification_report(l, predicted))\n",
    "print(\"Konfusionsmatrix:\\n\", metrics.confusion_matrix(l, predicted))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
