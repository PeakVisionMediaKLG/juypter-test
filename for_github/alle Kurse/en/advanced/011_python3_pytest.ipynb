{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytest\n",
    "### Introduction\n",
    "\n",
    "<img class=\"imgright\" src=\"../images/testing_pytest.webp\" srcset=\"../images/testing_pytest_350w.webp 350w,../images/testing_pytest_300w.webp 300w\" alt=\"testing with pytest\" /> \n",
    "\n",
    "pytest can be used for all types and levels of software testing. Many projects – amongst them Mozilla and Dropbox - switched from unittest or nose to pytest.\n",
    "\n",
    "### A Simple First Example with Pytest\n",
    "Test files which pytest will use for testing have to start with test_ or end with _test.py We will demonstrate the way of working by writing a test file test_fibonacci.py for a file fibonacci.py. Both files are in one directory:\n",
    "\n",
    "The first file is the file which should be tested. We assume that it is saved as fibonacci_p.py:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "def fib(n):\n",
    "    old, new = 0, 1\n",
    "    for _ in range(n):\n",
    "        old, new = new, old + new\n",
    "    return old\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to provide the code for the file test_fibonacci.py. This file will be used by 'pytest':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "from fibonacci_p import fib\n",
    "\n",
    "\n",
    "def test_fib():\n",
    "    assert fib(0) == 0\n",
    "    assert fib(1) == 1\n",
    "    assert fib(10) == 55\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call pytest in a command shell in the directory where the two file shown above reside:\n",
    "<pre> pytest </pre>\n",
    "The result of this code can be seen in the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.7.1, pytest-4.0.2, py-1.7.0, pluggy-0.8.0\n",
    "rootdir: /home/bernd/, inifile:\n",
    "plugins: remotedata-0.3.1, openfiles-0.3.1, doctestplus-0.2.0, arraydiff-0.3\n",
    "collected 1 item                                                               \n",
    "\n",
    "test_fibonacci.py .                                                      [100%]\n",
    "\n",
    "=========================== 1 passed in 0.01 seconds ===========================\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create now an erroneous version of fib. We change the two start values from 0 and 1 to the values 2 and 1. This is the beginning of the Lucas sequence, but as we want to implement the Fibonacci sequence this is wrong. This way, we can study how pytest behaves in this case:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "def fib(n):\n",
    "    old, new = 2, 1\n",
    "    for _ in range(n):\n",
    "        old, new = new, old + new\n",
    "    return old\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling 'pytest' with this erroneous implementation of fibonacci gives us the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "$ pytest  ============================= test session starts ==============================\n",
    "platform linux -- Python 3.7.1, pytest-4.0.2, py-1.7.0, pluggy-0.8.0\n",
    "rootdir: /home/bernd/, inifile:\n",
    "plugins: remotedata-0.3.1, openfiles-0.3.1, doctestplus-0.2.0, arraydiff-0.3\n",
    "collected 1 item                                                               \n",
    "\n",
    "test_fibonacci.py F                                                      [100%]\n",
    "\n",
    "=================================== FAILURES ===================================\n",
    "___________________________________ test_fib ___________________________________\n",
    "\n",
    "    def test_fib():\n",
    ">       assert fib(0) == 0\n",
    "E       assert 2 == 0\n",
    "E        +  where 2 = fib(0)\n",
    "\n",
    "test_fibonacci.py:5: AssertionError\n",
    "=========================== 1 failed in 0.03 seconds ===========================\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Pytest Example\n",
    "We will get closer to 'reality' in our next example. In a real life scenario, we will usually have more than one file and for each file we may have a corresponding test file. Each test file may contain various tests. We have various files in our example folder ex2:\n",
    "\n",
    "The files to be tested:\n",
    "\n",
    "- fibonacci.py\n",
    "- foobar_plus.py\n",
    "- foobar.py\n",
    "\n",
    "\n",
    "The test files:\n",
    "\n",
    "- test_fibonacci.py\n",
    "- test_foobar_plus.py\n",
    "- test_foobar.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start 'pytest' in the directory 'ex2' and get the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "$ pytest \n",
    "==================== test session starts ======================\n",
    "platform linux -- Python 3.7.3, pytest-4.3.1, py-1.8.0, pluggy-0.9.0\n",
    "rootdir: /home/bernd/ex2, inifile:\n",
    "plugins: remotedata-0.3.1, openfiles-0.3.2, doctestplus-0.3.0, arraydiff-0.3\n",
    "collected 4 items                                                              \n",
    "\n",
    "test_fibonacci.py .                                                      [ 25%]\n",
    "test_foobar.py ..                                                        [ 75%]\n",
    "test_foobar_plus.py .                                                    [100%]\n",
    "\n",
    "==================== 4 passed in 0.05 seconds =================\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Pytest Example\n",
    "It is possible to execute only tests, which contain a given substring in their name. The substring is determined by a Python expression This can be achieved with the call option „-k“\n",
    "<pre> pytest -k </pre>\n",
    "The call\n",
    "<pre> pytest -k foobar </pre>\n",
    "will only execute the test files having the substring 'foobar' in their name. In this case, they are test_foobar.py and test_foobar_plus.py:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "$ pytest -k foobar\n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.7.1, pytest-4.0.2, py-1.7.0, pluggy-0.8.0\n",
    "rootdir: /home/bernd/ex2, inifile:\n",
    "plugins: remotedata-0.3.1, openfiles-0.3.1, doctestplus-0.2.0, arraydiff-0.3\n",
    "collected 3 items / 1 deselected                                               \n",
    "\n",
    "test_foobar.py .                                                         [ 50%]\n",
    "test_foobar_plus.py .                                                    [100%]\n",
    "\n",
    "==================== 2 passed, 1 deselected in 0.01 seconds ====================\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select now only the files containing 'plus' and 'fibo'\n",
    "<pre> pytest -k 'plus or fibo' </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "$ pytest -k 'plus or fibo'\n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.7.1, pytest-4.0.2, py-1.7.0, pluggy-0.8.0\n",
    "rootdir: /home/bernd/ex2, inifile:\n",
    "plugins: remotedata-0.3.1, openfiles-0.3.1, doctestplus-0.2.0, arraydiff-0.3\n",
    "collected 3 items / 1 deselected                                               \n",
    "\n",
    "test_fibonacci.py .                                                      [ 50%]\n",
    "test_foobar_plus.py .                                                    [100%]\n",
    "\n",
    "==================== 2 passed, 1 deselected in 0.01 seconds ====================\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markers in Pytest\n",
    "Test functions can be marked or tagged by decorating them with 'pytest.mark.'.\n",
    "\n",
    "Such a marker can be used to select or deselect test functions. You can see the markers which exist for your test suite by typing\n",
    "\n",
    "<pre> $ pytest --markers </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "$ pytest --markers\n",
    "@pytest.mark.openfiles_ignore: Indicate that open files should be ignored for this test\n",
    "\n",
    "@pytest.mark.remote_data: Apply to tests that require data from remote servers\n",
    "\n",
    "@pytest.mark.internet_off: Apply to tests that should only run when network access is deactivated\n",
    "\n",
    "@pytest.mark.filterwarnings(warning): add a warning filter to the given test. see https://docs.pytest.org/en/latest/warnings.html#pytest-mark-filterwarnings \n",
    "\n",
    "@pytest.mark.skip(reason=None): skip the given test function with an optional reason. Example: skip(reason=\"no way of currently testing this\") skips the test.\n",
    "\n",
    "@pytest.mark.skipif(condition): skip the given test function if eval(condition) results in a True value.  Evaluation happens within the module global context. Example: skipif('sys.platform == \"win32\"') skips the test if we are on the win32 platform. see https://docs.pytest.org/en/latest/skipping.html\n",
    "\n",
    "@pytest.mark.xfail(condition, reason=None, run=True, raises=None, strict=False): mark the test function as an expected failure if eval(condition) has a True value. Optionally specify a reason for better reporting and run=False if you don't even want to execute the test function. If only specific exception(s) are expected, you can list them in raises, and if the test fails in other ways, it will be reported as a true failure. See https://docs.pytest.org/en/latest/skipping.html\n",
    "\n",
    "@pytest.mark.parametrize(argnames, argvalues): call a test function multiple times passing in different arguments in turn. argvalues generally needs to be a list of values if argnames specifies only one name or a list of tuples of values if argnames specifies multiple names. Example: @parametrize('arg1', [1,2]) would lead to two calls of the decorated test function, one with arg1=1 and another with arg1=2.see https://docs.pytest.org/en/latest/parametrize.html for more info and examples.\n",
    "\n",
    "@pytest.mark.usefixtures(fixturename1, fixturename2, ...): mark tests as needing all of the specified fixtures. see https://docs.pytest.org/en/latest/fixture.html#usefixtures \n",
    "\n",
    "@pytest.mark.tryfirst: mark a hook implementation function such that the plugin machinery will try to call it first/as early as possible.\n",
    "\n",
    "@pytest.mark.trylast: mark a hook implementation function such that the plugin machinery will try to call it last/as late as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains also custom defined markers!\n",
    "\n",
    "\n",
    "### Registering Markers\n",
    "Since pytest version 4.5 markers have to be registered.They can be registered in the init file pytest.ini, placed in the test directory.\n",
    "We register the markers 'slow' and 'crazy', which we will use in the following example:\n",
    "\n",
    "[pytest]\n",
    "markers =\n",
    "    slow: mark a test as a 'slow' (slowly) running test\n",
    "    crazy: stupid function to test :-)\n",
    "\n",
    "We add a recursive and inefficient version rfib to our fibonacci module and mark the corresponding test routine with slow, besides this rfib is marked with crazy as well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "# content of fibonacci.py\n",
    "\n",
    "def fib(n):\n",
    "    old, new = 0, 1\n",
    "    for i in range(n):\n",
    "        old, new = new, old + new\n",
    "    return old \n",
    "\n",
    "\n",
    "def rfib(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return rfib(n-1) + rfib(n-2)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding test file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\"\"\" content of test_fibonacci.py \"\"\"\n",
    "\n",
    "import pytest\n",
    "from fibonacci import fib, rfib\n",
    "\n",
    "def test_fib():\n",
    "    assert fib(0) == 0\n",
    "    assert fib(1) == 1\n",
    "    assert fib(34) == 5702887\n",
    "\n",
    "@pytest.mark.crazy\n",
    "@pytest.mark.slow\n",
    "def test_rfib():\n",
    "    assert fib(0) == 0\n",
    "    assert fib(1) == 1\n",
    "    assert rfib(34) == 5702887\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides this we will add the files foobar.py and test_foobar.py as well. We mark the test functions in test_foobar.py as crazy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# content of foobar.py\n",
    "\n",
    "def foo():\n",
    "    return \"foo\"\n",
    "\n",
    "def bar():\n",
    "    return \"bar\"\n",
    "</pre> \n",
    "\n",
    "This is the correponding test file:\n",
    "\n",
    "<pre>\n",
    "# content of test_foobar.py\n",
    "import pytest\n",
    "from foobar import foo, bar\n",
    "\n",
    "@pytest.mark.crazy\n",
    "def test_foo():\n",
    "    assert foo() == \"foo\"\n",
    "\n",
    "\n",
    "@pytest.mark.crazy\n",
    "def test_bar():\n",
    "    assert bar() == \"bar\"\n",
    "\n",
    "</pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start tests now depending on the markers.\n",
    "Let's start all tests, which are not marked as slow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "$ pytest -svv -k \"slow\"\n",
    "===================================== test session starts ======================================\n",
    "platform linux -- Python 3.7.1, pytest-4.0.2, py-1.7.0, pluggy-0.8.0 -- /home/bernd/python\n",
    "cachedir: .pytest_cache\n",
    "rootdir: /home/bernd/ex_tagging, inifile:\n",
    "plugins: remotedata-0.3.1, openfiles-0.3.1, doctestplus-0.2.0, arraydiff-0.3\n",
    "collected 4 items / 3 deselected                                                               \n",
    "\n",
    "test_fibonacci.py::test_rfib PASSED\n",
    "\n",
    "============================ 1 passed, 3 deselected in 7.05 seconds ============================\n",
    "</pre>\n",
    "\n",
    "We will run now only the tests which are not marked as slow or crazy:\n",
    "\n",
    "<pre>\n",
    "$ pytest -svv -k \"not slow and not crazy\"\n",
    "======================= test session starts =======================\n",
    "platform linux -- Python 3.7.1, pytest-4.0.2, py-1.7.0, pluggy-0.8.0 -- /home/bernd/\n",
    "cachedir: .pytest_cache\n",
    "rootdir: /home/bernd//ex_tagging, inifile:\n",
    "plugins: remotedata-0.3.1, openfiles-0.3.1, doctestplus-0.2.0, arraydiff-0.3\n",
    "collected 4 items / 3 deselected                                                               \n",
    "\n",
    "test_fibonacci.py::test_fib PASSED\n",
    "\n",
    "===================== 1 passed, 3 deselected in 0.01 seconds ====================\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skipif Marker\n",
    "If you wish to skip a function conditionally then you can use skipif. In the following example the function test_foo is marked with a skipif. The function will not be executed, if the Python version is 3.6.x:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "import pytest\n",
    "import sys\n",
    "from foobar import foo, bar\n",
    "\n",
    "\n",
    "@pytest.mark.skipif(\n",
    "    sys.version_info[0] == 3 and sys.version_info[1] == 6,\n",
    "    reason=\"Python version has to be higher than 3.5!\")\n",
    "def test_foo():\n",
    "    assert foo() == \"foo\"\n",
    "\n",
    "@pytest.mark.crazy\n",
    "def test_bar():\n",
    "    assert bar() == \"bar\"\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a conditional skip we can also use an unconditional skip. This way, we can always skip. We can add a reason. The following example shows how this can be accomplished by marking the function test_bar with a skip marker. The reason we give is that it is \"even fooer than foo\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "import pytest\n",
    "import sys\n",
    "from foobar import foo, bar\n",
    "\n",
    "@pytest.mark.skipif(\n",
    "    sys.version_info[0] == 3 and sys.version_info[1] == 6,\n",
    "    reason=\"Python version has to be higher than 3.5!\")\n",
    "def test_foo():\n",
    "    assert foo() == \"foo\"\n",
    "\n",
    "\n",
    "@pytest.mark.skip(reason=\"Even fooer than foo, so we skip!\")\n",
    "def test_bar():\n",
    "    assert bar() == \"bar\"\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call pytest on this code, we get the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "$ pytest -v\n",
    "================ test session starts ===============\n",
    "platform linux -- Python 3.6.9, pytest-5.0.1, py-1.8.0, pluggy-0.12.0 -- /home/bernd/python\n",
    "cachedir: .pytest_cache\n",
    "rootdir: /home/bernd/ex_tagging2, inifile: pytest.ini\n",
    "collected 4 items                                                                                                  \n",
    "\n",
    "test_fibonacci.py::test_fib PASSED                                                                           [ 25%]\n",
    "test_fibonacci.py::test_rfib PASSED                                                                          [ 50%]\n",
    "test_foobar.py::test_foo SKIPPED                                                                             [ 75%]\n",
    "test_foobar.py::test_bar PASSED                                                                              [100%]\n",
    "\n",
    "============= 3 passed, 1 skipped in 0.01 seconds =============\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrization with Markers\n",
    "We will demonstrate parametrization with markers with our Fibonacci function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# content of fibonacci.py\n",
    "\n",
    "def fib(n):\n",
    "    old, new = 0, 1\n",
    "    for _ in range(n):\n",
    "        old, new = new, old + new\n",
    "    return old \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a pytest test function which will test against this fibonacci function with various values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# content of the file test_fibonacci.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "from fibonacci import fib\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    'n, res', [(0, 0), \n",
    "               (1, 1), \n",
    "               (2, 1),\n",
    "               (3, 2), \n",
    "               (4, 3),\n",
    "               (5, 5),\n",
    "               (6, 8)])\n",
    "def test_fib(n, res):\n",
    "    assert fib(n) == res\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call pytest, we get the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "$ pytest -v\n",
    "============================ test session starts ============================\n",
    "platform linux -- Python 3.6.9, pytest-5.0.1, py-1.8.0, pluggy-0.12.0 -- /home/bernd/python\n",
    "cachedir: .pytest_cache\n",
    "rootdir: /home/bernd/ex_parametrization1\n",
    "collected 7 items                                                                              \n",
    "\n",
    "test_fibonacci.py::test_fib[0-0] PASSED                                                  [ 14%]\n",
    "test_fibonacci.py::test_fib[1-1] PASSED                                                  [ 28%]\n",
    "test_fibonacci.py::test_fib[2-1] PASSED                                                  [ 42%]\n",
    "test_fibonacci.py::test_fib[3-2] PASSED                                                  [ 57%]\n",
    "test_fibonacci.py::test_fib[4-3] PASSED                                                  [ 71%]\n",
    "test_fibonacci.py::test_fib[5-5] PASSED                                                  [ 85%]\n",
    "test_fibonacci.py::test_fib[6-8] PASSED                                                  [100%]\n",
    "\n",
    "========================== 7 passed in 0.01 seconds =========================\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers inside the square brackets on front of the word \"PASSED\" are the values of 'n' and 'res'.\n",
    "\n",
    "### Prints in Functions\n",
    "If there are prints in the functions which we test, we will not see this output in our pytests, unless we call pytest with the option \"-s\".\n",
    "To demonstrate this we will add a print line to our fibonacci function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "def fib(n):\n",
    "    old, new = 0, 1\n",
    "    for _ in range(n):\n",
    "        old, new = new, old + new\n",
    "    print(\"result: \", old)\n",
    "    return old\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling \"pytest -s -v\" will deliver the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "=============== test session starts ==============\n",
    "platform linux -- Python 3.6.9, pytest-5.0.1, py-1.8.0, pluggy-0.12.0 -- /home/bernd/python\n",
    "cachedir: .pytest_cache\n",
    "rootdir: /home/bernd/ex_parametrization1\n",
    "collected 7 items                                                                              \n",
    "\n",
    "test_fibonacci.py::test_fib[0-0] result:  0\n",
    "PASSED\n",
    "test_fibonacci.py::test_fib[1-1] result:  1\n",
    "PASSED\n",
    "test_fibonacci.py::test_fib[2-1] result:  1\n",
    "PASSED\n",
    "test_fibonacci.py::test_fib[3-2] result:  2\n",
    "PASSED\n",
    "test_fibonacci.py::test_fib[4-3] result:  3\n",
    "PASSED\n",
    "test_fibonacci.py::test_fib[5-5] result:  5\n",
    "PASSED\n",
    "test_fibonacci.py::test_fib[6-8] result:  8\n",
    "PASSED\n",
    "\n",
    "============= 7 passed in 0.01 seconds =================\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line Options / Fixtures\n",
    "We will write a test version for our fibonacci function which depends on command line arguments. We can add custom command line options to pytest with the pytest_addoption hook that allows us to manage the command line parser and the setup for each test.\n",
    "At first, we have to write a file conftest.py with the functions cmdopt and pytest_addoption:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "import pytest\n",
    "\n",
    "def pytest_addoption(parser):\n",
    "    parser.addoption(\"--cmdopt\", \n",
    "                     action=\"store\", \n",
    "                     default=\"full\", \n",
    "                     help=\"'num' of tests or full\")\n",
    "\n",
    "@pytest.fixture\n",
    "def cmdopt(request):\n",
    "    return request.config.getoption(\"--cmdopt\")\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for our fibonacci test module looks like. The test_fif function has a parameter 'cmdopt' which gets the parameter option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "from fibonacci import fib\n",
    "\n",
    "results = [0, 1, 1, 2, 3, 5, 8, 13, 21, \n",
    "           34, 55, 89, 144, 233, 377]\n",
    "\n",
    "\n",
    "def test_fib(cmdopt):\n",
    "    if cmdopt == \"full\":\n",
    "        num = len(results)\n",
    "    else:\n",
    "        num = len(results)\n",
    "        if int(cmdopt) < len(results):\n",
    "            num = int(cmdopt)\n",
    "    for i in range(num):\n",
    "        assert fib(i) == results[i] </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call it now with various options, as we can see in the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "$ pytest -q --cmdopt=full -v -s\n",
    "============ test session starts ================\n",
    "platform linux -- Python 3.6.9, pytest-5.0.1, py-1.8.0, pluggy-0.12.0\n",
    "rootdir: /home/bernd/Dropbox (Bodenseo)/kurse/python_en/examples/pytest/ex_cmd_line\n",
    "collected 1 item                                                                               \n",
    "\n",
    "test_fibonacci.py running 15 tests!\n",
    ".\n",
    "\n",
    "============= 1 passed in 0.01 seconds ============\n",
    "\n",
    "\n",
    "\n",
    "$ pytest -q --cmdopt=6 -v -s\n",
    "============= test session starts ==============\n",
    "platform linux -- Python 3.6.9, pytest-5.0.1, py-1.8.0, pluggy-0.12.0\n",
    "rootdir: /home/bernd/Dropbox (Bodenseo)/kurse/python_en/examples/pytest/ex_cmd_line\n",
    "collected 1 item                                                                               \n",
    "\n",
    "test_fibonacci.py running  6 tests!\n",
    ".\n",
    "\n",
    "=========================== 1 passed in 0.01 seconds ================================\n",
    "\n",
    "</pre>\n",
    "\n",
    "Let's put an error in our test results:\n",
    "results = [0, 1, 1, 2, 3, 1001, 8,…]\n",
    "Calling pytest with 'pytest -q --cmdopt=10 -v -s' gives us the following output:\n",
    "\n",
    "<pre>\n",
    "================== test session starts ================== \n",
    "platform linux -- Python 3.6.9, pytest-5.0.1, py-1.8.0, pluggy-0.12.0 rootdir: /home/bernd/ex_cmd_line collected 1 item test_fibonacci.py running 10 tests! F =============== FAILURES =================== _______________ test_fib ___________________ cmdopt = '10' def test_fib(cmdopt): if cmdopt == \"full\": num = len(results) else: num = len(results) if int(cmdopt) < len(results): num = int(cmdopt) print(f\"running {num:2d} tests!\") for i in range(num): > assert fib(i) == results[i] E assert 5 == 1001 E + where 5 = fib(5) test_fibonacci.py:16: AssertionError ================ 1 failed in 0.03 seconds =================\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
