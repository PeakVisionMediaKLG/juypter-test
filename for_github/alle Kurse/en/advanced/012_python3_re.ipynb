{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "<img height= 200 width=200 class=\"imgright\" src=\"../images/RE.webp\" srcset=\"../images/RE_350w.webp 350w,../images/RE_300w.webp 300w\" alt=\"Text with RE\" />\n",
    "The aim of this chapter of our Python tutorial is to present a detailed and descriptive introduction into regular expressions. This introduction will explain the theoretical aspects of regular expressions and will show you how to use them in Python scripts.\n",
    "\n",
    "The term \"regular expression\", sometimes also called regex or regexp, has originated in theoretical computer science. In theoretical computer science, they are used to define a language family with certain characteristics, the so-called regular languages. A finite state machine (FSM), which accepts language defined by a regular expression, exists for every regular expression. You can find an implementation of a [Finite State Machine in Python](https://www.python-course.eu/finite_state_machine.php) on our website.\n",
    "\n",
    "Regular Expressions are used in programming languages to filter texts or textstrings. It's possible to check, if a text or a string matches a regular expression. A great thing about regular expressions: The syntax of regular expressions is the same for all programming and script languages, e.g. Python, Perl, Java, SED, AWK and even X#.\n",
    "\n",
    "The first programs which had incorporated the capability to use regular expressions were the Unix tools ed (editor), the stream editor sed and the filter grep.\n",
    "\n",
    "There is another mechanism in operating systems, which shouldn't be mistaken for regular expressions. Wildcards, also known as globbing, look very similar in their syntax to regular expressions. However, the semantics differ\n",
    "considerably. Globbing is known from many command line shells, like the Bourne shell, the Bash shell or even DOS. In Bash e.g. the command \"ls *.txt\" lists all files (or even directories) ending with the suffix .txt; in regular expression notation \"*.txt\" wouldn't make sense, it would have to be written as \".*.txt\"\n",
    "\n",
    "### Introduction\n",
    "When we introduced the sequential data types, we got to know the \"in\" operator. We check in the following example, if the string \"easily\" is a substring of the string \"Regular expressions easily explained!\":\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Regular expressions easily explained!\"\n",
    "\"easily\" in s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show step by step with the following diagrams how this matching is performed:\n",
    "We check if the string sub = \"abc\"\n",
    "\n",
    "<img height= 30 src=\"../images/regular_expression2.webp\" alt=\"Substring bzw. Regulärer Ausdruck\" />\n",
    "\n",
    "is contained in the string s = \"xaababcbcd\"\n",
    "\n",
    "<img height= 30 src=\"../images/regular_expression1.webp\" srcset=\"../images/regular_expression1_400w.webp 400w,../images/regular_expression1_350w.webp 350w,../images/regular_expression1_300w.webp 300w\" alt=\"Ein String in dem ein RE gesucht wird\" /> \n",
    "\n",
    "By the way, the string sub = \"abc\" can be seen as a regular expression, just a very simple one.\n",
    "\n",
    "In the first place, we check, if the first positions of the two string match, i.e. s[0] == sub[0].\n",
    "This is not satisfied in our example. We mark this fact by the colour red:\n",
    "\n",
    "<img height= 60 src=\"../images/regular_expression3.webp\" srcset=\"../images/regular_expression3_400w.webp 400w,../images/regular_expression3_350w.webp 350w,../images/regular_expression3_300w.webp 300w\" alt=\"Comparisons of the first positions\" /> \n",
    "\n",
    "Then we check, if s[1:4] == sub. In other words, we have to check at first, if sub[0] is equal to s[1]. This is true and we mark it with the colour green. Then, we have to compare the next positions. s[2] is not equal to sub[1], so we don't have to proceed further with the next position of sub and s:\n",
    "\n",
    "<img height= 60 src=\"../images/regular_expression4.webp\" srcset=\"../images/regular_expression4_400w.webp 400w,../images/regular_expression4_350w.webp 350w,../images/regular_expression4_300w.webp 300w\" alt=\"Nächster Schritt\" /> \n",
    "\n",
    "Now we have to check if s[2:5] and sub are equal. The first two positions are equal but not the third:\n",
    "\n",
    "<img height= 60 src=\"../images/regular_expression5.webp\" srcset=\"../images/regular_expression5_400w.webp 400w,../images/regular_expression5_350w.webp 350w,../images/regular_expression5_300w.webp 300w\" alt=\"Nächster Schritt\" /> \n",
    "\n",
    "The following steps should be clear without any explanations:\n",
    "\n",
    "<img height= 60 src=\"../images/regular_expression6.webp\" srcset=\"../images/regular_expression6_400w.webp 400w,../images/regular_expression6_350w.webp 350w,../images/regular_expression6_300w.webp 300w\" alt=\"Nächster Schritt\" /> \n",
    "\n",
    "Finally, we have a complete match with s[4:7] == sub :\n",
    "\n",
    "<img height= 60 src=\"../images/regular_expression7.webp\" srcset=\"../images/regular_expression7_400w.webp 400w,../images/regular_expression7_350w.webp 350w,../images/regular_expression7_300w.webp 300w\" alt=\"Nächster Schritt\" /> \n",
    "\n",
    "### A Simple Regular Expression\n",
    "As we have already mentioned in the previous section, we can see the variable \"sub\" from the introduction as a very simple regular expression.\n",
    "If you want to use regular expressions in Python, you have to import the re module, which provides methods and functions to deal with regular expressions.\n",
    "\n",
    "### Representing Regular Expressions in Python\n",
    "From other languages you might be used to representing regular expressions within Slashes \"/\", e.g. that's the way Perl, SED or AWK deals with them. In Python there is no special notation. Regular expressions are represented as normal strings.\n",
    "\n",
    "But this convenience brings along a small problem: The backslash is a special character used in regular expressions, but is also used as an escape character in strings. This implies that Python would first evaluate every backslash of a string and after this - without the necessary backslashes - it would be used as a regular expression. One way to prevent this could be writing every backslash as \"\\\\\" and this way keep it for the evaluation of the regular expression. This can cause extremely clumsy expressions. E.g. a backslash in a regular expression has to be written as a double backslash, because the backslash functions as an escape character in regular expressions. Therefore, it has to be quoted. The same is valid for Python strings. The backslash has to be quoted by a backslash. So, a regular expression to match the Windows path \"C:\\programs\" corresponds to a string in regular expression notation with four backslashes, i.e. \"C:\\\\\\\\programs\".\n",
    "\n",
    "The best way to overcome this problem would be marking regular expressions as raw strings. The solution to our Windows path example looks like this as a raw string:\n",
    "\n",
    "<pre>\n",
    "r\"C:\\\\programs\"\n",
    "</pre>\n",
    "\n",
    "Let's look at another example, which might be quite disturbing for people who are used to wildcards:\n",
    "\n",
    "<pre>\n",
    "r\"^a.*\\.html$\"\n",
    "</pre>\n",
    "\n",
    "The regular expression of our previous example matches all file names (strings) which start with an \"a\" and end with \".html\". We will the structure of the example above in detail explain in the following sections.\n",
    "\n",
    "### Syntax of Regular Expression\n",
    "\n",
    "<img class= \"imgright\" src=\"../images/re_matching_problem.webp\" alt=\"Matching Problem\" /> \n",
    "\n",
    "<pre> r\"cat\" </pre> is a regular expression, though a very simple one without any metacharacters. Our RE <pre> r\"cat\" </pre> matches, for example, the following string: \"A cat and a rat can't be friends.\"\n",
    "\n",
    "Interestingly, the previous example shows already a \"favourite\" example for a mistake, frequently made not only by beginners and novices but also by advanced users of regular expressions. The idea of this example is to match strings containing the word \"cat\". We are successful at this, but unfortunately we are matching a lot of other words as well. If we match \"cats\" in a string that might be still okay, but what about all those words containing this character sequence \"cat\"? We match words like \"education\", \"communicate\", \"falsification\", \"ramifications\", \"cattle\" and many more. This is a case of \"over matching\", i.e. we receive positive results, which are wrong according to the problem we want to solve.\n",
    "\n",
    "We have illustrated this problem in the diagram above. The dark green Circle C corresponds to the set of \"objects\" we want to recognize. But instead we match all the elements of the set O (blue circle). C is a subset of O.\n",
    "The set U (light green circle) in this diagram is a subset of C. U is a case of \"under matching\", i.e. if the regular expression is not matching all the intended strings. If we try to fix the previous RE, so that it doesn't create over matching, we might try the expression <pre> r\" cat \" </pre>. These blanks prevent the matching of the above mentioned words like \"education\", \"falsification\" and \"ramification\", but we fall prey to another mistake. What about the string \"The cat, called Oscar, climbed on the roof.\"? The problem is that we don't expect a comma but only a blank surrounding the word \"cat\".\n",
    "\n",
    "Before we go on with the description of the syntax of regular expressions, we want to explain how to use them in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(2, 5), match='cat'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "x = re.search(\"cat\", \"A cat and a rat can't be friends.\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = re.search(\"cow\", \"A cat and a rat can't be friends.\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example we had to import the module re to be able to work with regular expressions. Then we used the method search from the re module. This is most probably the most important and the most often used method of this module. re.search(expr,s) checks a string s for an occurrence of a substring which matches the regular expression expr. The first substring (from left), which satisfies this condition will be returned. If a match has been possible, we get a so-called match object as a result, otherwise the value will be None. This method is already enough to use regular expressions in a basic way in Python programs. We can use it in conditional statements: If a regular expression matches, we get an SRE object returned, which is taken as a True value, and None, which is the return value if it doesn't match, is taken as False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some kind of cat has been found :-)\n"
     ]
    }
   ],
   "source": [
    "if re.search(\"cat\", \"A cat and a rat can't be friends.\"):\n",
    "    print(\"Some kind of cat has been found :-)\")\n",
    "else:\n",
    "    print(\"No cat has been found :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cow around.\n"
     ]
    }
   ],
   "source": [
    "if re.search(\"cow\", \"A cat and a rat can't be friends.\"):\n",
    "     print(\"Cats and Rats and a cow.\")\n",
    "else:\n",
    "     print(\"No cow around.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any Character\n",
    "Let's assume that we have not been interested in the previous example to recognize the word cat, but all three letter words, which end with \"at\".\n",
    "The syntax of regular expressions supplies a metacharacter \".\", which is used like a placeholder for \"any character\". The regular expression of our example can be written like this:\n",
    "r\" .at \"\n",
    "This RE matches three letter words, isolated by blanks, which end in \"at\". Now we get words like \"rat\", \"cat\", \"bat\", \"eat\", \"sat\" and many others.\n",
    "\n",
    "But what if the text contains \"words\" like \"@at\" or \"3at\"? These words match as well, meaning we have caused over matching again. We will learn a solution in the following section. \n",
    "\n",
    "#### Character Classes\n",
    "Square brackets, \"[\" and \"]\", are used to include a character class. [xyz] means e.g. either an \"x\", an \"y\" or a \"z\".\n",
    "Let's look at a more practical example:\n",
    "\n",
    "<pre> r\"M[ae][iy]er\" </pre>\n",
    "\n",
    "This is a regular expression, which matches a surname which is quite common in German. A name with the same pronunciation and four different spellings: Maier, Mayer, Meier, Meyer\n",
    "A finite state automata to recognize this expression can be build like this:\n",
    "\n",
    "<img width=90% src=\"../images/finite_state_machine_mayer.webp\" srcset=\"../images/finite_state_machine_mayer_400w.webp 400w,../images/finite_state_machine_mayer_350w.webp 350w,../images/finite_state_machine_mayer_300w.webp 300w\" alt=\"Finite State Machine, Mayer\" /> \n",
    "\n",
    "The graph of the finite state machine (FSM) is simplified to keep the design easy. There should be an arrow in the start node pointing back on its own, i.e. if a character other than an upper case \"M\" has been processed, the machine should stay in the start condition. Furthermore, there should be an arrow pointing back from all nodes except the final nodes (the green ones) to the start node, unless the expected letter has been processed. E.g. if the machine is in state Ma, after having processed a \"M\" and an \"a\", the machine has to go back to state \"Start\", if any character except \"i\" or \"y\" can be read. Those who have problems with this FSM, shouldn't worry, since it is not a prerequisite for the rest of the chapter. \n",
    "\n",
    "Instead of a choice between two characters, we often need a choice between larger character classes. We might need e.g. a class of letters between \"a\" and \"e\" or between \"0\" and \"5\". To manage such character classes, the syntax of regular expressions supplies a metacharacter \"-\". [a-e] a simplified writing for [abcde] or [0-5] denotes [012345].\n",
    "\n",
    "The advantage is obvious and even more impressive, if we have to coin expressions like \"any uppercase letter\" into regular expressions. So instead of [ABCDEFGHIJKLMNOPQRSTUVWXYZ] we can write [A-Z]. If this is not convincing: Write an expression for the character class \"any lower case or uppercase letter\" [A-Za-z]\n",
    "\n",
    "\n",
    "There is something more about the dash, we used to mark the begin and the end of a character class. The dash has only a special meaning if it is used within square brackets and in this case only if it isn't positioned directly after an opening or immediately in front of a closing bracket.\n",
    "So the expression [-az] is only the choice between the three characters \"-\", \"a\" and \"z\", but no other characters. The same is true for [az-].\n",
    "\n",
    "Exercise:\n",
    "What character class is described by [-a-z]?\n",
    "\n",
    "Answer The character \"-\" and all the characters \"a\", \"b\", \"c\" all the way up to \"z\".\n",
    "\n",
    "The only other special character inside square brackets (character class choice) is the caret \"^\". If it is used directly after an opening sqare bracket, it negates the choice. [^0-9] denotes the choice \"any character but a digit\". The position of the caret within the square brackets is crucial. If it is not positioned as the first character following the opening square bracket, it has no special meaning.\n",
    "[^abc] means anything but an \"a\", \"b\" or \"c\"\n",
    "[a^bc] means an \"a\", \"b\", \"c\" or a \"^\"\n",
    "\n",
    "#### A Practical Exercise in Python\n",
    "Before we go on with our introduction into regular expressions, we want to insert a practical exercise with Python.\n",
    "We have a phone list of the Simpsons, yes, the famous Simpsons from the American animated TV series. There are some people with the surname Neu. We are looking for a Neu, but we don't know the first name, we just know that it starts with a J. Let's write a Python script, which finds all the lines of the phone book, which contain a person with the described surname and a first name starting with J. If you don't know how to read and work with files, you should work through our chapter [File Management](https://www.python-course.eu/python3_file_management.php). So here is our example script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack Neu 555-7666\n",
      "Jeb Neu 555-5543\n",
      "Jennifer Neu 555-3652\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "fh = open(\"simpsons_phone_book.txt\")\n",
    "for line in fh:\n",
    "    if re.search(r\"J.*Neu\",line):\n",
    "        print(line.rstrip())\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of downloading simpsons_phone_book.txt, we can also use the file directly from the website by using urlopen from the module urllib.request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack Neu 555-7666\n",
      "Jeb Neu 555-5543\n",
      "Jennifer Neu 555-3652\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from urllib.request import urlopen\n",
    "with urlopen('https://www.python-course.eu/simpsons_phone_book.txt') as fh:\n",
    "    for line in fh:\n",
    "        # line is a byte string so we transform it to utf-8:\n",
    "        line = line.decode('utf-8').rstrip() \n",
    "        if re.search(r\"J.*Neu\",line):\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predefined Character Classes\n",
    "You might have realized that it can be quite cumbersome to construe certain character classes. A good example is the character class, which describes a valid word character. These are all lower case and uppercase characters plus all the digits and the underscore, corresponding to the following regular expression: r\"[a-zA-Z0-9_]\"\n",
    "\n",
    "<pre>\n",
    "The special sequences consist of \"\\\\\" and a character from the following list:\n",
    "\\d \tMatches any decimal digit; equivalent to the set [0-9].\n",
    "\\D \tThe complement of \\d. It matches any non-digit character; equivalent to the set [^0-9].\n",
    "\\s \tMatches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v].\n",
    "\\S \tThe complement of \\s. It matches any non-whitespace character; equiv. to [^ \\t\\n\\r\\f\\v].\n",
    "\\w \tMatches any alphanumeric character; equivalent to [a-zA-Z0-9_]. With LOCALE, it will match the set [a-zA-Z0-9_] plus characters defined as letters for the current locale.\n",
    "\\W \tMatches the complement of \\w.\n",
    "\\b \tMatches the empty string, but only at the start or end of a word.\n",
    "\\B \tMatches the empty string, but not at the start or end of a word.\n",
    "\\\\ \tMatches a literal backslash.\n",
    "</pre>\n",
    "\n",
    "#### Word boundaries\n",
    "The \\b and \\B of the previous overview of special sequences, is often not properly understood or even misunderstood especially by novices. While the other sequences match characters, - e.g. \\w matches characters like \"a\", \"b\", \"m\", \"3\" and so on, - \\b and \\B don't match a character. They match empty strings depending on their neighbourhood, i.e. what kind of a character the predecessor and the successor is. So \\b matches any empty string between a \\W and a \\w character and also between a \\w and a \\W character. \\B is the complement, i.e empty strings between \\W and \\W or empty strings between \\w and \\w. We illustrate this in the following example:\n",
    "\n",
    "<img width= 95%\" src=\"../images/word_boundary.webp\" srcset=\"../images/word_boundary_500w.webp 500w,../images/word_boundary_400w.webp 400w,../images/word_boundary_350w.webp 350w,../images/word_boundary_300w.webp 300w\" alt=\"word boundaries: \\b and \\B illustrated\" /> \n",
    "\n",
    "We will get to know further \"virtual\" matching characters, i.e. the caret (^), which is used to mark the beginning of a string, and the dollar sign ($), which is used to mark the end of a string, respectively. \\A and \\Z, which can also be found in our previous diagram, are very seldom used as alternatives to the caret and the dollar sign.\n",
    "\n",
    "### Matching Beginning and End\n",
    "As we have previously carried out in this introduction, the expression r\"M[ae][iy]er\" is capable of matching various spellings of the name Mayer and the name can be anywhere in the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found one!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "line = \"He is a German called Mayer.\"\n",
    "if re.search(r\"M[ae][iy]er\", line): \n",
    "    print(\"I found one!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to match a regular expression at the beginning of a string and only at the beginning?\n",
    "\n",
    "The re module of Python provides two functions to match regular expressions. We have met already one of them, i.e. search(). The other has in our opinion a misleading name: match() Misleading, because match(re_str, s) checks for a match of re_str merely at the beginning of the string. But anyway, match() is the solution to our question, as we can see in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 5), match='Mayer'>\n",
      "<re.Match object; span=(13, 18), match='Meyer'>\n",
      "<re.Match object; span=(0, 5), match='Mayer'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s1 = \"Mayer is a very common Name\"\n",
    "s2 = \"He is called Meyer but he isn't German.\"\n",
    "print(re.search(r\"M[ae][iy]er\", s1))\n",
    "print(re.search(r\"M[ae][iy]er\", s2))\n",
    " # matches because it starts with Mayer\n",
    "print(re.match(r\"M[ae][iy]er\", s1)) \n",
    "# doesn't match because it doesn't start with Meyer or Meyer, Meier and so on:\n",
    "print(re.match(r\"M[ae][iy]er\", s2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is a way to match the start of a string, but it's a Python specific method, i.e. it can't be used in other languages like Perl, AWK and so on. There is a general solution which is a standard for regular expressions:\n",
    "\n",
    "The caret '^' matches the start of the string, and in MULTILINE (will be explained further down) mode also matches immediately after each newline, which the Python method match() doesn't do.\n",
    "The caret has to be the first character of a regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 5), match='Mayer'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s1 = \"Mayer is a very common Name\"\n",
    "s2 = \"He is called Meyer but he isn't German.\"\n",
    "print(re.search(r\"^M[ae][iy]er\", s1))\n",
    "print(re.search(r\"^M[ae][iy]er\", s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens if we concatenate the two strings s1 and s2 in the following way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s2 + \"\\n\" + s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the string doesn't start with a Maier of any kind, but the name follows a newline character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "s = s2 + \"\\n\" + s1\n",
    "print(re.search(r\"^M[ae][iy]er\", s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name hasn't been found, because only the beginning of the string is checked. It changes, if we use the multiline mode, which can be activated by adding the following parameters to search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(40, 45), match='Mayer'>\n",
      "<re.Match object; span=(40, 45), match='Mayer'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(re.search(r\"^M[ae][iy]er\", s, re.MULTILINE))\n",
    "print(re.search(r\"^M[ae][iy]er\", s, re.M))\n",
    "print(re.match(r\"^M[ae][iy]er\", s, re.M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous example also shows that the multiline mode doesn't affect the match method. match() never checks anything but the beginning of the string for a match.\n",
    "\n",
    "We have learnt how to match the beginning of a string. What about the end? Of course that's possible to. The dollar sign _\"\"isusedasametacharacterforthispurpose.′'_ matches the end of a string or just before the newline at the end of the string. If in MULTILINE mode, it also matches before a newline. We demonstrate the usage of the \"$\" character in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 14), match='Python.'>\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(7, 14), match='Python.'>\n"
     ]
    }
   ],
   "source": [
    "print(re.search(r\"Python\\.$\",\"I like Python.\"))\n",
    "print(re.search(r\"Python\\.$\",\"I like Python and Perl.\"))\n",
    "print(re.search(r\"Python\\.$\",\"I like Python.\\nSome prefer Java or Perl.\"))\n",
    "print(re.search(r\"Python\\.$\",\"I like Python.\\nSome prefer Java or Perl.\", re.M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional Items\n",
    "If you thought that our collection of Mayer names was complete, you were wrong. There are other ones all over the world, e.g. London and Paris, who dropped their \"e\". So we have four more names [\"Mayr\", \"Meyr\", \"Meir\", \"Mair\"] plus our old set [\"Mayer\", \"Meyer\", \"Meier\", \"Maier\"].\n",
    "\n",
    "If we try to figure out a fitting regular expression, we realize that we miss something. A way to tell the computer \"this \"e\" may or may not occur\". A question mark is used as a notation for this. A question mark declares that the preceding character or expression is optional.\n",
    "\n",
    "The final Mayer-Recognizer looks now like this:\n",
    "<pre>\n",
    "r\"M[ae][iy]e?r\"\n",
    "</pre>\n",
    "\n",
    "A subexpression is grouped by round brackets and a question mark following such a group means that this group may or may not exist. With the following expression we can match dates like \"Feb 2011\" or February 2011\":\n",
    "<pre>\n",
    "r\"Feb(ruary)? 2011\"\n",
    "</pre>\n",
    "\n",
    "#### Quantifiers\n",
    "If you just use what we have introduced so far, you will still need a lot of things, above all some way of repeating characters or regular expressions. For this purpose, quantifiers are used. We have encountered one in the previous paragraph, i.e. the question mark.\n",
    "\n",
    "A quantifier after a token, which can be a single character or group in brackets, specifies how often that preceding element is allowed to occur. The most common quantifiers are\n",
    "\n",
    "- the question mark ?\n",
    "- the asterisk or star character *, which is derived from the Kleene star\n",
    "- and the plus sign +, derived from the Kleene cross\n",
    "\n",
    "We have already previously used one of these quantifiers without explaining it, i.e. the asterisk. A star following a character or a subexpression group means that this expression or character may be repeated arbitrarily, even zero times.\n",
    "<pre>\n",
    "r\"[0-9]*\"\n",
    "</pre>\n",
    "\n",
    "The above expression matches any sequence of digits, even the empty string. r\".*\" matches any sequence of characters and the empty string.\n",
    "\n",
    "**Exercise**:\n",
    "Write a regular expression which matches strings which starts with a sequence of digits - at least one digit - followed by a blank.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "   <pre>\n",
    "r\"^[0-9][0-9]* \"\n",
    "    \n",
    "   </pre>\n",
    "\n",
    "So, you used the plus character \"+\". That's fine, but in this case you have either cheated by going ahead in the text or you know already more about regular expressions than we have covered in our course :-)\n",
    "\n",
    "Now that we mentioned it: The plus operator is very convenient to solve the previous exercise. The plus operator is very similar to the star operator, except that the character or subexpression followed by a \"+\" sign has to be repeated at least one time. Here follows the solution to our exercise with the plus quantifier:\n",
    "\n",
    "**Solution with the plus quantifier**:\n",
    "\n",
    "<pre>\n",
    "    r\"^[0-9]+ \"\n",
    "   \n",
    "</pre>\n",
    "\n",
    "If you work with this arsenal of operators for a while, you will inevitably miss the possibility to repeat expressions for an exact number of times at some point. Let's assume you want to recognize the last lines of addresses on envelopes in Switzerland. These lines usually contain a four digits long post code followed by a blank and a city name. Using + or * are too unspecific for our purpose and the following expression seems to be too clumsy:\n",
    "\n",
    "   <pre>\n",
    "r\"^[0-9][0-9][0-9][0-9] [A-Za-z]+\"\n",
    "    </pre>\n",
    "\n",
    "Fortunately, there is an alternative available:\n",
    "    \n",
    "   <pre>\n",
    "r\"^[0-9]{4} [A-Za-z]*\"    </pre>\n",
    "\n",
    "Now we want to improve our regular expression. Let's assume that there is no city name in Switzerland, which consists of less than 3 letters, at least 3 letters. We can denote this by [A-Za-z]{3,}. Now we have to recognize lines with German post code (5 digits) lines as well, i.e. the post code can now consist of either four or five digits:\n",
    "\n",
    "   <pre>\n",
    "r\"^[0-9]{4,5} [A-Z][a-z]{2,}\" </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general syntax is {from, to}, meaning the expression has to appear at least \"from\" times and not more than \"to\" times. {, to} is an abbreviated spelling for {0,to} and {from,} is an abbreviation for \"at least from times but no upper limit\"\n",
    "\n",
    "#### Grouping\n",
    "We can group a part of a regular expression by surrounding it with parenthesis (round brackets). This way we can apply operators to the complete group instead of a single character.\n",
    "#### Capturing Groups and Back References\n",
    "Parenthesis (round brackets, braces) are not only group subexpressions but they also create back references. The part of the string matched by the grouped part of the regular expression, i.e. the subexpression in parenthesis, is stored in a back reference. With the aid of back references we can reuse parts of regular expressions. These stored values can be both reused inside the expression itself and afterwards, when the regexpr is executed. Before we continue with our treatise about back references, we want to strew in a paragraph about match objects, which is important for our next examples with back references.\n",
    "\n",
    "#### A Closer Look at the Match Objects\n",
    "So far we have just checked, if an expression matched or not. We used the fact the re.search() returns a match object if it matches and None otherwise. We haven't been interested e.g. in what has been matched. The match object contains a lot of data about what has been matched, positions and so on.\n",
    "\n",
    "A match object contains the methods group(), span(), start() and end(), as it can be seen in the following application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'232454'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "mo = re.search(\"[0-9]+\", \"Customer number: 232454, Date: February 12, 2011\")\n",
    "mo.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 23)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.span()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.span()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods are not difficult to understand. span() returns a tuple with the start and end position, i.e. the string index where the regular expression started matching in the string and ended matching. The methods start() and end() are in a way superfluous as the information is contained in span(), i.e. span()[0] is equal to start() and span()[1] is equal to end(). group(), if called without argument, it returns the substring, which had been matched by the complete regular expression. With the help of group() we are also capable of accessing the matched substring by grouping parentheses, to get the matched substring of the n-th group, we call group() with the argument n: group(n).\n",
    "We can also call group with more than integer argument, e.g. group(n,m). group(n,m) - provided there exists a subgoup n and m - returns a tuple with the matched substrings. group(n,m) is equal to (group(n), group(m)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'232454, Date: February 12, 2011'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "mo = re.search(\"([0-9]+).*: (.*)\", \"Customer number: 232454, Date: February 12, 2011\")\n",
    "mo.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'232454'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'February 12, 2011'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('232454', 'February 12, 2011')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very intuitive example are XML or HTML tags. E.g. let's assume we have a file (called \"tags.txt\") with content like this:\n",
    "\n",
    "\n",
    "    <composer> Wolfgang Amadeus Mozart </composer>\n",
    "    <author> Samuel Beckett </author>\n",
    "    <city> London </city>\n",
    "\n",
    "\n",
    "\n",
    "We want to rewrite this text automatically to\n",
    "\n",
    "<pre>\n",
    "composer: Wolfgang Amadeus Mozart\n",
    "author: Samuel Beckett\n",
    "city: London\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following little Python script does the trick. The core of this script is the regular expression. This regular expression works like this: It tries to match a less than symbol \"<\". After this it is reading lower case letters until it reaches the greater than symbol. Everything encountered within \"<\" and \">\" has been stored in a back reference which can be accessed within the expression by writing \\1. Let's assume \\1 contains the value \"composer\". When the expression has reached the first \">\", it continues matching, as the original expression had been \"<composer>(.*)</composer>\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composer:  Wolfgang Amadeus Mozart \n",
      "author:  Samuel Beckett \n",
      "city:  London \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "fh = open(\"tags.txt\")\n",
    "for i in fh:\n",
    "     res = re.search(r\"<([a-z]+)>(.*)</\\1>\",i)\n",
    "     print(res.group(1) + \": \" + res.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are more than one pair of parenthesis (round brackets) inside the expression, the backreferences are numbered \\1, \\2, \\3, in the order of the pairs of parenthesis.\n",
    "\n",
    "**Exercise:** \n",
    "The next Python example makes use of three back references. We have an imaginary phone list of the Simpsons in a list. Not all entries contain a phone number, but if a phone number exists it is the first part of an entry. Then, separated by a blank, a surname follows, which is followed by first names. Surname and first name are separated by a comma. The task is to rewrite this example in the following way:\n",
    "<pre>\n",
    "Allison Neu 555-8396\n",
    "C. Montgomery Burns \n",
    "Lionel Putz 555-5299\n",
    "Homer Jay Simpson 555-73347\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python script solving the rearrangement problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allison Neu 555-8396\n",
      "C. Montgomery Burns \n",
      "Lionel Putz 555-5299\n",
      "Homer Jay Simpson 555-7334\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "l = [\"555-8396 Neu, Allison\", \n",
    "     \"Burns, C. Montgomery\", \n",
    "     \"555-5299 Putz, Lionel\",\n",
    "     \"555-7334 Simpson, Homer Jay\"]\n",
    "\n",
    "for i in l:\n",
    "    res = re.search(r\"([0-9-]*)\\s*([A-Za-z]+),\\s+(.*)\", i)\n",
    "    print(res.group(3) + \" \" + res.group(2) + \" \" + res.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Backreferences\n",
    "In the previous paragraph we introduced \"Capturing Groups\" and \"Back references\". More precisely, we could have called them \"Numbered Capturing Groups\" and \"Numbered Backreferences\".\n",
    "Using capturing groups instead of \"numbered\" capturing groups allows you to assign descriptive names instead of automatic numbers to the groups. In the following example, we demonstrate this approach by catching the hours, minutes and seconds from a UNIX date string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "s = \"Sun Oct 14 13:47:03 CEST 2012\"\n",
    "expr = r\"\\b(?P<hours>\\d\\d):(?P<minutes>\\d\\d):(?P<seconds>\\d\\d)\\b\"\n",
    "x = re.search(expr,s)\n",
    "x.group('hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'47'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.group('minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.start('minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.end('minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 19)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.span('seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehensive Python Exercise\n",
    "In this comprehensive exercise, we have to bring the information of two files together. In the first file, we have a list of nearly 15000 lines of post codes with the corresponding city names plus additional information. Here are some arbitrary lines of this file:\n",
    "<pre>\n",
    "osm_id ort plz bundesland\n",
    "1104550 Aach 78267 Baden-Württemberg\n",
    "...\n",
    "446465 Freiburg (Elbe) 21729 Niedersachsen\n",
    "62768 Freiburg im Breisgau 79098 Baden-Württemberg\n",
    "62768 Freiburg im Breisgau 79100 Baden-Württemberg\n",
    "62768 Freiburg im Breisgau 79102 Baden-Württemberg\n",
    "...\n",
    "454863 Fulda 36037 Hessen\n",
    "454863 Fulda 36039 Hessen\n",
    "454863 Fulda 36041 Hessen\n",
    "...\n",
    "1451600 Gallin 19258 Mecklenburg-Vorpommern\n",
    "449887 Gallin-Kuppentin 19386 Mecklenburg-Vorpommern\n",
    "...\n",
    "57082 Gärtringen 71116 Baden-Württemberg\n",
    "1334113 Gartz (Oder) 16307 Brandenburg\n",
    "...\n",
    "2791802 Giengen an der Brenz 89522 Baden-Württemberg\n",
    "2791802 Giengen an der Brenz 89537 Baden-Württemberg\n",
    "...\n",
    "1187159 Saarbrücken 66133 Saarland\n",
    "1256034 Saarburg 54439 Rheinland-Pfalz\n",
    "1184570 Saarlouis 66740 Saarland\n",
    "1184566 Saarwellingen 66793 Saarland </pre>\n",
    "\n",
    "The other file contains a list of the 19 largest German cities. Each line consists of the rank, the name of the city, the population, and the state (Bundesland):\n",
    "\n",
    "<pre>\n",
    "1.  Berlin          3.382.169 Berlin\n",
    "2.  Hamburg         1.715.392 Hamburg\n",
    "3.  München         1.210.223 Bayern\n",
    "4.  Köln              962.884 Nordrhein-Westfalen\n",
    "5.  Frankfurt am Main 646.550 Hessen\n",
    "6.  Essen             595.243 Nordrhein-Westfalen\n",
    "7.  Dortmund          588.994 Nordrhein-Westfalen\n",
    "8.  Stuttgart         583.874 Baden-Württemberg\n",
    "9.  Düsseldorf        569.364 Nordrhein-Westfalen\n",
    "10. Bremen            539.403 Bremen\n",
    "11. Hannover          515.001 Niedersachsen\n",
    "12. Duisburg          514.915 Nordrhein-Westfalen\n",
    "13. Leipzig           493.208 Sachsen\n",
    "14. Nürnberg          488.400 Bayern\n",
    "15. Dresden           477.807 Sachsen\n",
    "16. Bochum            391.147 Nordrhein-Westfalen\n",
    "17. Wuppertal         366.434 Nordrhein-Westfalen\n",
    "18. Bielefeld         321.758 Nordrhein-Westfalen\n",
    "19. Mannheim          306.729 Baden-Württemberg \n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to create a list with the top 19 cities, with the city names accompanied by the postal code. If you want to test the following program, you have to save the list above in a file called largest_cities_germany.txt and you have to download and save the list of [German post codes](https://www.python-course.eu/post_codes_germany.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin {'12685', '12279', '12353', '12681', '13465', '12163', '10365', '12351', '13156', '12629', '12689', '12053', '13086', '12057', '12157', '10823', '12621', '14129', '13359', '13435', '10963', '12209', '12683', '10369', '10787', '12277', '14059', '12459', '13593', '12687', '10785', '12526', '10717', '12487', '12203', '13583', '12347', '12627', '10783', '12559', '14050', '10969', '10367', '12207', '13409', '10555', '10623', '10249', '10315', '12109', '12055', '13353', '13509', '10407', '12051', '12159', '10629', '13503', '13591', '10961', '10777', '13439', '13057', '10999', '12309', '12437', '10781', '12305', '10965', '12167', '10318', '10409', '12359', '10779', '14169', '10437', '12161', '10589', '13581', '12679', '13505', '12555', '10405', '10119', '13355', '10179', '12357', '13469', '13351', '14055', '14089', '10627', '10829', '12107', '12435', '10319', '13507', '10551', '13437', '13347', '13627', '12524', '13599', '13189', '13129', '13467', '12589', '12489', '10825', '13585', '10625', '12527', '13405', '10439', '13597', '10317', '10553', '12101', '10557', '12355', '13587', '13053', '10967', '12439', '13589', '10707', '13629', '13088', '10719', '10243', '12045', '12105', '12349', '13125', '10117', '14199', '13187', '13357', '13349', '13403', '10178', '12047', '13055', '12165', '12249', '13407', '12169', '12587', '14053', '14052', '12103', '10245', '14193', '12205', '10827', '10585', '10587', '12557', '10435', '12623', '10713', '12059', '13059', '14109', '13051', '13127', '12307', '10715', '14057', '14195', '12619', '13158', '12043', '13089', '10711', '10997', '12099', '10247', '10709', '13595', '14165', '12247', '13159', '14167', '10789', '12049', '14197', '10559', '10115', '14163'}\n",
      "Hamburg {'22589', '22305', '22587', '22395', '20457', '22391', '22763', '20359', '22393', '22527', '20249', '22605', '21037', '27499', '22547', '20097', '22147', '20255', '22765', '22115', '22309', '20259', '22767', '20095', '22399', '22113', '22087', '21129', '22299', '22159', '22083', '22455', '20144', '21033', '22119', '20354', '22145', '22041', '22049', '21035', '21077', '20099', '20459', '20149', '21031', '22453', '20539', '21039', '22297', '22149', '20251', '22607', '22529', '22179', '21075', '22339', '22397', '22335', '22047', '22175', '22085', '21079', '22303', '22111', '22525', '21107', '20537', '22143', '21029', '22081', '20253', '22301', '22337', '21109', '22459', '20355', '22559', '22549', '22761', '21149', '20357', '22415', '22307', '22177', '22045', '20146', '22457', '22089', '22417', '22769', '22419', '22117', '22609', '20535', '21073', '20257', '22523', '22359', '20148', '22043', '21147'}\n",
      "München {'81241', '81669', '80336', '80796', '80799', '80339', '80539', '80689', '80939', '81929', '80634', '81249', '81545', '80469', '81475', '80803', '81371', '81373', '81476', '80686', '80999', '81667', '81927', '80804', '81739', '80997', '80687', '80798', '80933', '81477', '81541', '81369', '81379', '81549', '81675', '80637', '80801', '80992', '80993', '81377', '81543', '81677', '81925', '81479', '81247', '80337', '81673', '85540', '80802', '80797', '80333', '80638', '81827', '81671', '80809', '80639', '81547', '81825', '81245', '81829', '81243', '81375', '81737', '80805', '80335', '81679', '80331', '80636', '80935', '80538', '80807', '80937', '81539', '80995', '81735'}\n",
      "Köln {'50939', '50827', '50668', '50676', '50999', '51065', '50968', '50733', '50937', '50769', '51147', '50670', '51061', '50823', '50767', '50829', '50674', '51069', '50735', '50672', '50679', '50737', '50931', '50678', '50969', '51103', '50667', '50858', '50859', '50933', '51105', '51467', '51063', '51107', '50825', '50996', '51109', '51145', '50935', '50765', '51067', '50997', '51149', '50739', '50677', '51143'}\n",
      "Frankfurt am Main {'60437', '60311', '60439', '60329', '60549', '60320', '60322', '60486', '65934', '60489', '60599', '60438', '60431', '60594', '60529', '60488', '60386', '60310', '60306', '60325', '60313', '60598', '65931', '60389', '60308', '65936', '60327', '60435', '60385', '60316', '60596', '60433', '60318', '60528', '65933', '60487', '60314', '60388', '60323', '65929', '60326'}\n",
      "Essen {'45259', '45276', '45327', '45145', '45138', '45355', '45219', '45257', '45326', '45141', '45128', '45277', '45130', '45289', '45279', '45139', '45307', '45356', '45136', '45144', '45239', '45357', '45147', '45131', '45359', '45127', '45329', '45309', '45134', '45143', '45133', '45149'}\n",
      "Dortmund {'44139', '44263', '44141', '44267', '44265', '44319', '44145', '44289', '44339', '44229', '44309', '44357', '44147', '44379', '44143', '44149', '44227', '44328', '44135', '44359', '44137', '44329', '44269', '44287', '44369', '44388', '44225'}\n",
      "Stuttgart {'70191', '70186', '70193', '70195', '70176', '70378', '70197', '70327', '70435', '70192', '70376', '70182', '70174', '70569', '70190', '70188', '70597', '70374', '70567', '70499', '70599', '70184', '70329', '70178', '70565', '70563', '70439', '70629', '70469', '70619', '70199', '70372', '70173', '70180', '70437'}\n",
      "Düsseldorf {'40227', '40215', '40549', '40225', '40593', '40476', '40625', '40231', '40595', '40221', '40217', '40229', '40470', '40721', '40489', '40627', '40479', '40212', '40211', '40219', '40235', '40547', '40223', '40477', '40629', '40233', '40599', '40589', '40597', '40213', '40237', '40472', '40474', '40468', '40591', '40210', '40545', '40239'}\n",
      "Bremen {'28195', '28201', '28215', '27568', '28759', '28307', '28755', '28217', '28279', '28777', '28213', '28719', '28325', '28197', '28779', '28757', '28209', '28309', '28207', '28219', '28277', '28203', '28199', '28327', '28237', '28205', '28211', '28329', '28717', '28357', '28359', '28355', '28239', '28259'}\n",
      "Hannover {'30459', '30519', '30627', '30669', '30539', '30419', '30177', '30521', '30629', '30559', '30453', '30655', '30659', '30169', '30455', '30449', '30179', '30175', '30625', '30159', '30451', '30171', '30457', '30657', '30165', '30173', '30161', '30163', '30167'}\n",
      "Duisburg {'47249', '47229', '47055', '47179', '47138', '47139', '47198', '47057', '47166', '47199', '47279', '47169', '47259', '47269', '47228', '47137', '47226', '47119', '47051', '47167', '47058', '47059', '47239', '47178', '47053'}\n",
      "Leipzig {'4155', '4289', '4357', '4205', '4349', '4229', '4288', '4275', '4209', '4179', '4347', '4328', '4177', '4129', '4319', '4178', '4318', '4277', '4315', '4103', '4105', '4317', '4249', '4316', '4158', '4329', '4109', '4356', '4279', '4107', '4207', '4159', '4157', '4299'}\n",
      "Nürnberg {'90480', '90482', '90427', '90475', '90411', '90471', '90439', '90403', '90478', '90451', '90443', '90431', '90453', '90473', '90459', '90469', '90402', '90408', '90455', '90489', '90441', '90449', '90461', '90419', '90491', '90425', '90409', '90429'}\n",
      "Dresden {'1159', '1139', '1326', '1187', '1156', '1069', '1108', '1099', '1465', '1109', '1127', '1169', '1324', '1328', '1259', '1277', '1239', '1257', '1237', '1217', '1157', '1097', '1219', '1307', '1309', '1129', '1189', '1279', '1067'}\n",
      "Bochum {'44869', '44809', '44799', '44787', '44803', '44867', '44801', '44866', '44795', '44894', '44793', '44805', '44807', '44791', '44879', '44797', '44892', '44789'}\n",
      "Wuppertal {'42389', '42399', '42327', '42115', '42107', '42279', '42109', '42103', '42369', '42111', '42275', '42117', '42113', '42283', '42281', '42329', '42105', '42289', '42119', '42277', '42287', '42349', '42285'}\n",
      "Bielefeld {'33613', '33699', '33729', '33611', '33602', '33615', '33739', '33605', '33659', '33609', '33689', '33617', '33647', '33619', '33719', '33607', '33604', '33649'}\n",
      "Mannheim {'68199', '68309', '68239', '68305', '68161', '68167', '68165', '68229', '68159', '68307', '68163', '68259', '68169', '68219'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(\"zuordnung_plz_ort.txt\", encoding=\"utf-8\") as fh_post_codes:\n",
    "    codes4city = {}\n",
    "    for line in fh_post_codes:\n",
    "        res = re.search(r\"[\\d ]+([^\\d]+[a-z])\\s(\\d+)\", line)\n",
    "        if res:\n",
    "            city, post_code = res.groups()\n",
    "            if city in codes4city:\n",
    "                codes4city[city].add(post_code) \n",
    "            else:\n",
    "                codes4city[city] = {post_code}\n",
    "\n",
    "with open(\"largest_cities_germany.txt\", encoding=\"utf-8\") as fh_largest_cities:\n",
    "    for line in fh_largest_cities:\n",
    "        re_obj = re.search(r\"^[0-9]{1,2}\\.\\s+([\\w\\s-]+\\w)\\s+[0-9]\", line)\n",
    "        city = re_obj.group(1)\n",
    "        print(city, codes4city[city])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another Comprehensive Example\n",
    "We want to present another real life example in our Python course. A regular expression for UK postcodes.We write an expression, which is capable of recognizing the postal codes or postcodes of the UK.\n",
    "\n",
    "Postcode units consist of between five and seven characters, which are separated into two parts by a space. The two to four characters before the space represent the so-called outward code or out code intended to directly mail from the sorting office to the delivery office. The part following the space, which consists of a digit followed by two uppercase characters, comprises the so-called inward code, which is needed to sort mail at the final delivery office. The last two uppercase characters do not use the letters CIKMOV, so as not to resemble digits or each other when hand-written.\n",
    "\n",
    "The outward code can have the following form: One or two uppercase characters, followed by either a digit or the letter R, optionally followed by an uppercase character or a digit. (We do not consider all the detailed rules for postcodes, i.e only certain character sets are valid depending on the position and the context.)A regular expression for matching this superset of UK postcodes looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> r\"\\b[A-Z]{1,2}[0-9R][0-9A-Z]? [0-9][ABD-HJLNP-UW-Z]{2}\\b\" </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Python program uses the regexp above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW1A 0AA matched!\n",
      "SW1A 1AA matched!\n",
      "SW1A 2AA matched!\n",
      "BX3 2BB matched!\n",
      "DH98 1BT matched!\n",
      "N1 9GU matched!\n",
      "E98 1TT matched!\n",
      "TIM E22 is not a valid postcode!\n",
      "A B1 A22 is not a valid postcode!\n",
      "EC2N 2DB matched!\n",
      "SE9 2UG matched!\n",
      "N1 0UY matched!\n",
      "EC1V 8DS matched!\n",
      "WC1X 9DT matched!\n",
      "B42 1LG matched!\n",
      "B28 9AD matched!\n",
      "W12 7RJ matched!\n",
      "BBC 007 is not a valid postcode!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "example_codes = [\"SW1A 0AA\", # House of Commons\n",
    "                 \"SW1A 1AA\", # Buckingham Palace\n",
    "                 \"SW1A 2AA\", # Downing Street\n",
    "                 \"BX3 2BB\", # Barclays Bank\n",
    "                 \"DH98 1BT\", # British Telecom\n",
    "                 \"N1 9GU\", # Guardian Newspaper\n",
    "                 \"E98 1TT\", # The Times\n",
    "                 \"TIM E22\", # a fake postcode\n",
    "                 \"A B1 A22\", # not a valid postcode\n",
    "                 \"EC2N 2DB\", # Deutsche Bank\n",
    "                 \"SE9 2UG\", # University of Greenwhich\n",
    "                 \"N1 0UY\", # Islington, London\n",
    "                 \"EC1V 8DS\", # Clerkenwell, London\n",
    "                 \"WC1X 9DT\", # WC1X 9DT\n",
    "                 \"B42 1LG\", # Birmingham\n",
    "                 \"B28 9AD\", # Birmingham\n",
    "                 \"W12 7RJ\", # London, BBC News Centre\n",
    "                 \"BBC 007\" # a fake postcode\n",
    "                ]\n",
    "\n",
    "pc_re = r\"[A-z]{1,2}[0-9R][0-9A-Z]? [0-9][ABD-HJLNP-UW-Z]{2}\"\n",
    "\n",
    "for postcode in example_codes:\n",
    "    r = re.search(pc_re, postcode)\n",
    "    if r:\n",
    "        print(postcode + \" matched!\")\n",
    "    else:\n",
    "        print(postcode + \" is not a valid postcode!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
