{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "### Introduction\n",
    "<img width=\"60%\" class=\"imgright\"  src=\"../images/sniper.webp\" srcset=\"../images/sniper_700w.webp 700w,../images/sniper_600w.webp 600w,../images/sniper_500w.webp 500w,../images/sniper_400w.webp 400w,../images/sniper_350w.webp 350w,../images/sniper_300w.webp 300w\" alt=\"sniper\" />\n",
    "\n",
    "\n",
    "Not only in machine learning but also in general life, especially business life, you will hear questiones like \"How accurate is your product?\" or \"How precise is your machine?\". When people get replies like \"This is the most accurate product in its field!\" or \"This machine has the highest imaginable precision!\", they feel fomforted by both answers. Shouldn't they? Indeed, the terms ```accurate``` and ```precise``` are very often used interchangeably. We will give exact definitions later in the text, but in a nutshell, we can say: Accuracy is a measure for the closeness of some measurements to a specific value, while precision is the closeness of the measurements to each other.\n",
    "\n",
    "These terms are also of extreme importance in Machine Learning. We need them for evaluating ML algorithms or better their results.\n",
    "\n",
    "We will present in this chapter of our Python Machine Learning Tutorial four important metrics. These metrics are used to evaluate the results of classifications.\n",
    "The metrics are:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "\n",
    "We will introduce each of these metrics and we will discuss the pro and cons of each of them. \n",
    "Each metric measures something different about a classifiers performance. The metrics will be of outmost importance for all the chapters of our machine learning tutorial.\n",
    "\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "\n",
    "Accuracy is a measure for the closeness of the measurements to a specific value, while precision is the closeness of the measurements to each other, i.e. not necessarily to a specific value. To put it in other words: If we have a set of data points from repeated measurements of the same quantity, the set is said to be accurate if their average is close to the true value of the quantity being measured. On the other hand, we call the set to be precise, if the values are close to each other. The two concepts are independent of each other, which means that the set of data can be accurate, or precise, or both, or neither. We show this in the following diagram:\n",
    "\n",
    "<img width=\"80%\"  src=\"../images/accuracy_vs_precision.webp\" srcset=\"../images/accuracy_vs_precision_800w.webp 800w,../images/accuracy_vs_precision_700w.webp 700w,../images/accuracy_vs_precision_600w.webp 600w,../images/accuracy_vs_precision_500w.webp 500w,../images/accuracy_vs_precision_400w.webp 400w,../images/accuracy_vs_precision_350w.webp 350w,../images/accuracy_vs_precision_300w.webp 300w\" alt=\"accuracy versus precision\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Before we continue with the term ```accuracy```, we want to make sure that you understand what a confusion matrix is about. \n",
    "\n",
    "A confusion matrix, also called a contingeny table or error matrix, is used to visualize the performance of a classifier.\n",
    "\n",
    "The columns of the matrix represent the instances of the predicted classes and the rows represent the instances of the actual class. (Note: It can be the other way around as well.)\n",
    "\n",
    "In the case of binary classification the table has 2 rows and 2 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to demonstrate the concept with an example.\n",
    "\n",
    "<p>Example:</p>\n",
    "<p><style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hcxd{font-weight:bold;background-color:#003532;color:#ffcc67;vertical-align:top}\n",
    ".tg .tg-2de4{background-color:#c0c0c0;color:#000000;text-align:right;vertical-align:top}\n",
    ".tg .tg-lqy6{text-align:right;vertical-align:top}\n",
    ".tg .tg-5mgg{font-weight:bold;background-color:#c0c0c0;vertical-align:top}\n",
    ".tg .tg-n17z{font-weight:bold;background-color:#013300;color:#ffcc67;vertical-align:top}\n",
    ".tg .tg-ddj9{background-color:#c0c0c0;color:#000000;text-align:center;vertical-align:top}\n",
    ".tg .tg-wsyr{background-color:#c0c0c0;color:#333333;vertical-align:top}\n",
    "</style></p>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-5mgg\" colspan=\"2\" rowspan=\"2\">Confusion<br>Matrix<br></th>\n",
    "    <th class=\"tg-n17z\" colspan=\"2\">Predicted classes<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-ddj9\">cat</td>\n",
    "    <td class=\"tg-2de4\">dog<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td class=\"tg-hcxd\" rowspan=\"2\">\n",
    "  <div style=\"display: inline-block; -ms-transform: rotate(-90deg); -webkit-transform: rotate(90deg); transform: rotate(90deg);;\">Actual<br>\n",
    "classes</div><br></td>\n",
    "    <td class=\"tg-wsyr\">cat</td>\n",
    "    <td class=\"tg-baqh\">42</td>\n",
    "    <td class=\"tg-lqy6\">8<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-wsyr\">dog</td>\n",
    "    <td class=\"tg-baqh\">18</td>\n",
    "    <td class=\"tg-lqy6\">32</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<p>This means that the classifier correctly predicted a cat in 42 cases and it wrongly predicted 8 cat instances as dog.\n",
    "It correctly predicted 32 instances as dog. 18 cases had been wrongly predicted as cat instead of dog.</p>\n",
    "\n",
    "\n",
    "### Accuracy in Classification\n",
    "\n",
    "We are interested in Machine Learning and accuracy is also used as a statistical measure. \n",
    "Accuracy is a statistical measure which is defined as the quotient of correct predictions (both True positives (TP) and True negatives (TN)) made by a classifier divided by the sum of all predictions made by the classifier, including False positves (FP) and False negatives (FN). Therefore, the formula for quantifying binary accuracy is:\n",
    "<br><br>\n",
    "$$ accuracy = {{TP + TN} \\over {TP + TN + FP + FN}} $$\n",
    "\n",
    "where: TP = True positive; FP = False positive; TN = True negative; FN = False negative \n",
    "\n",
    "The corresponding Confusion Matrix looks like this:\n",
    "<br><br>\n",
    "\n",
    "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-5mgg\" colspan=\"2\" rowspan=\"2\">Confusion<br>Matrix<br></th>\n",
    "    <th class=\"tg-n17z\" colspan=\"2\">Predicted classes<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-ddj9\">negative</td>\n",
    "    <td class=\"tg-2de4\">positive<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td class=\"tg-hcxd\" rowspan=\"2\"><b>\n",
    "  <div style=\"display: inline-block; -ms-transform: rotate(-90deg); -webkit-transform: rotate(90deg); transform: rotate(90deg);;\">Actual<br>\n",
    "classes</div></b><br></td>\n",
    "    <td class=\"tg-wsyr\">negative</td>\n",
    "    <td class=\"tg-baqh\">TN</td>\n",
    "    <td class=\"tg-lqy6\">FP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-wsyr\">positive</td>\n",
    "    <td class=\"tg-baqh\">FN</td>\n",
    "    <td class=\"tg-lqy6\">TP</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the accuracy for the cat-and-dog classification results. Instead of \"True\" and \"False\", we see here \"cat\" and \"dog\". We can calculate the accuracy like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "TP = 42\n",
    "TN = 32\n",
    "FP = 8\n",
    "FN = 18\n",
    "\n",
    "Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's assume we have a classifier, which always predicts \"dog\".</p>\n",
    "\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-5mgg\" colspan=\"2\" rowspan=\"2\">Confusion<br>Matrix<br></th>\n",
    "    <th class=\"tg-n17z\" colspan=\"2\">Predicted classes<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-ddj9\">cat</td>\n",
    "    <td class=\"tg-2de4\">dog<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td class=\"tg-hcxd\" rowspan=\"2\">\n",
    "  <div style=\"display: inline-block; -ms-transform: rotate(-90deg); -webkit-transform: rotate(90deg); transform: rotate(90deg);;\">Actual<br>\n",
    "classes</div><br></td>\n",
    "    <td class=\"tg-wsyr\">cat</td>\n",
    "    <td class=\"tg-baqh\">0</td>\n",
    "    <td class=\"tg-lqy6\">50<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-wsyr\">dog</td>\n",
    "    <td class=\"tg-baqh\">0</td>\n",
    "    <td class=\"tg-lqy6\">50</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "We have an accuracy of 0.5 in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = 0, 50, 50, 0\n",
    "Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Paradox\n",
    "\n",
    "\n",
    "<p>We will demonstrate the so-called accuracy paradox.</p>\n",
    "<p>A spam recogition classifier is described by the following confusion matrix:</p>\n",
    "\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-5mgg\" colspan=\"2\" rowspan=\"2\">Confusion<br>Matrix<br></th>\n",
    "    <th class=\"tg-n17z\" colspan=\"2\">Predicted classes<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-ddj9\">spam</td>\n",
    "    <td class=\"tg-2de4\">ham<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td class=\"tg-hcxd\" rowspan=\"2\">\n",
    "  <div style=\"display: inline-block; -ms-transform: rotate(-90deg); -webkit-transform: rotate(90deg); transform: rotate(90deg);;\">Actual<br>\n",
    "classes</div><br></td>\n",
    "    <td class=\"tg-wsyr\">spam</td>\n",
    "    <td class=\"tg-baqh\">4</td>\n",
    "    <td class=\"tg-lqy6\">1<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-wsyr\">ham</td>\n",
    "    <td class=\"tg-baqh\">4</td>\n",
    "    <td class=\"tg-lqy6\">91</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = 4, 91, 1, 4\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The following classifier predicts solely \"ham\" and has the same accuracy.</p>\n",
    "\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-5mgg\" colspan=\"2\" rowspan=\"2\">Confusion<br>Matrix<br></th>\n",
    "    <th class=\"tg-n17z\" colspan=\"2\">Predicted classes<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-ddj9\">spam</td>\n",
    "    <td class=\"tg-2de4\">ham<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td class=\"tg-hcxd\" rowspan=\"2\">\n",
    "  <div style=\"display: inline-block; -ms-transform: rotate(-90deg); -webkit-transform: rotate(90deg); transform: rotate(90deg);;\">Actual<br>\n",
    "classes</div><br></td>\n",
    "    <td class=\"tg-wsyr\">spam</td>\n",
    "    <td class=\"tg-baqh\">0</td>\n",
    "    <td class=\"tg-lqy6\">5<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-wsyr\">ham</td>\n",
    "    <td class=\"tg-baqh\">0</td>\n",
    "    <td class=\"tg-lqy6\">95</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "TP, TN, FP, FN = 0, 95, 5, 0\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The accuracy of this classifier is 95%, even though it is not capable of recognizing any spam at all.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "Precision is the ratio of the correctly identified positive cases to all the predicted positive cases, i.e. the correctly and the incorrectly cases predicted as ```positive```. Precision is the fraction of retrieved documents that are relevant to the query. The formula:\n",
    "\n",
    "$$ precision = {TP \\over {TP + FP}}$$\n",
    "\n",
    "We will demonstrate this with an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-5mgg\" colspan=\"2\" rowspan=\"2\">Confusion<br>Matrix<br></th>\n",
    "    <th class=\"tg-n17z\" colspan=\"2\">Predicted classes<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-ddj9\">spam</td>\n",
    "    <td class=\"tg-2de4\">ham<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td class=\"tg-hcxd\" rowspan=\"2\">\n",
    "  <div style=\"display: inline-block; -ms-transform: rotate(-90deg); -webkit-transform: rotate(90deg); transform: rotate(90deg);;\">Actual<br>\n",
    "classes</div><br></td>\n",
    "    <td class=\"tg-wsyr\">spam</td>\n",
    "    <td class=\"tg-baqh\">12</td>\n",
    "    <td class=\"tg-lqy6\">14<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-wsyr\">ham</td>\n",
    "    <td class=\"tg-baqh\">0</td>\n",
    "    <td class=\"tg-lqy6\">114</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the ```precision``` for our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.89\n"
     ]
    }
   ],
   "source": [
    "TP = 114\n",
    "FP = 14\n",
    "# FN (0) and TN (12) are not needed in the formuala!\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"precision: {precision:4.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Before you go on with the text think about what the value ```precision``` means. If you look at the precision measure of our spam filter example, what does it tell you about the quality of the spam filter? \n",
    "What do the results of the confusion matrix of an ideal spam filter look like? What is worse, high FP or FN values?\n",
    "\n",
    "You will find the answers indirectly in the following explanations. \n",
    "\n",
    "Incidentally, the ideal spam filter would have 0 values for both FP and FN.\n",
    "\n",
    "The previous result means that 11 mailpieces out of a hundred will be classified as ham, even though they are spam. 89 are correctly classified as ham. This is a point where we should talk about the costs of misclassification. It is troublesome when a spam mail is not recognized as \"spam\" and is instead presented to us as \"ham\". If the percentage is not too high, it is annoying but not a disaster. In contrast, when a non-spam message is wrongly labeled as spam, the email will not be shown in many cases or even automatically deleted. For example, this carries a high risk of losing customers and friends.\n",
    "The measure ```precision``` makes no statement about this last-mentioned problem class. What about other measures?\n",
    "\n",
    "We will have a look at ```recall``` and ```F1-score```.\n",
    "\n",
    "### Recall\n",
    "\n",
    "Recall, also known as sensitivity, is the ratio of the correctly identified positive cases to all the actual positive cases, which is the sum of the \"False Negatives\" and \"True Positives\". \n",
    "<br><br>\n",
    "\n",
    "$$ recall = {TP \\over {TP + FN}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "TP = 114\n",
    "FN = 0\n",
    "# FT (14) and TN (12) are not needed in the formuala!\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"recall: {recall:4.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value 1 means that no non-spam message is wrongly labeled as spam. It is important for a good spam filter that this value should be 1. We have previously discussed this already.\n",
    "\n",
    "### F1-score\n",
    "\n",
    "The last measure, we will examine, is the F1-score.\n",
    "<br><br>\n",
    "\n",
    "$$ F_1 = {2 \\over {{1 \\over recall} + {1 \\over precision}}} = 2 \\cdot {{{precision}\\cdot{recall}} \\over {{precision} + {recall}}  }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FN    FP   TP     pre   acc   rec   f1\n",
      "  0.00  0.00 93.00  1.00  1.00  1.00  1.00\n",
      "  1.00  0.00 92.00  1.00  0.99  0.99  0.99\n",
      "  1.00  1.00 91.00  0.99  0.99  0.99  0.99\n",
      "  2.00  0.00 91.00  1.00  0.99  0.98  0.99\n",
      "  2.00  1.00 90.00  0.99  0.98  0.98  0.98\n",
      "  2.00  2.00 89.00  0.98  0.98  0.98  0.98\n",
      "  3.00  0.00 90.00  1.00  0.98  0.97  0.98\n",
      "  3.00  1.00 89.00  0.99  0.98  0.97  0.98\n",
      "  3.00  2.00 88.00  0.98  0.97  0.97  0.97\n",
      "  3.00  3.00 87.00  0.97  0.97  0.97  0.97\n",
      "  4.00  0.00 89.00  1.00  0.98  0.96  0.98\n",
      "  4.00  1.00 88.00  0.99  0.97  0.96  0.97\n",
      "  4.00  2.00 87.00  0.98  0.97  0.96  0.97\n",
      "  4.00  3.00 86.00  0.97  0.96  0.96  0.96\n",
      "  4.00  4.00 85.00  0.96  0.96  0.96  0.96\n",
      "  5.00  0.00 88.00  1.00  0.97  0.95  0.97\n",
      "  5.00  1.00 87.00  0.99  0.97  0.95  0.97\n",
      "  5.00  2.00 86.00  0.98  0.96  0.95  0.96\n",
      "  5.00  3.00 85.00  0.97  0.96  0.94  0.96\n",
      "  5.00  4.00 84.00  0.95  0.95  0.94  0.95\n",
      "  5.00  5.00 83.00  0.94  0.95  0.94  0.94\n",
      "  6.00  0.00 87.00  1.00  0.97  0.94  0.97\n",
      "  6.00  1.00 86.00  0.99  0.96  0.93  0.96\n",
      "  6.00  2.00 85.00  0.98  0.96  0.93  0.96\n",
      "  6.00  3.00 84.00  0.97  0.95  0.93  0.95\n",
      "  6.00  4.00 83.00  0.95  0.95  0.93  0.94\n",
      "  6.00  5.00 82.00  0.94  0.94  0.93  0.94\n",
      "  6.00  6.00 81.00  0.93  0.94  0.93  0.93\n"
     ]
    }
   ],
   "source": [
    "TF = 7 # we set the True false values to 5 %\n",
    "print(\"  FN    FP   TP     pre   acc   rec   f1\")\n",
    "for FN in range(0, 7):\n",
    "    for FP in range(0, FN+1):\n",
    "        # the sum of FN, FP, TF and TP will be 100:\n",
    "        TP = 100 - FN - FP - TF\n",
    "        #print(FN, FP, TP, FN+FP+TP+TF)\n",
    "        precision = TP / (TP + FP)\n",
    "        accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = 2 * precision * recall / (precision + recall)\n",
    "        print(f\"{FN:6.2f}{FP:6.2f}{TP:6.2f}\", end=\"\")\n",
    "        print(f\"{precision:6.2f}{accuracy:6.2f}{recall:6.2f}{f1_score:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that ```f1-score``` best reflects the worse case scenario that the FN value is rising, i.e. ham is getting classified as spam!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
