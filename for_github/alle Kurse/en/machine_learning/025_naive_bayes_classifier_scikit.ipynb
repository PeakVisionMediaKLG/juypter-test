{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier with Scikit\n",
    "\n",
    "<img width=\"60%\" class=\"imgright\" src=\"../images/classifiers_off_the_rack.webp\" srcset=\"../images/classifiers_off_the_rack_500w.webp 500w,../images/classifiers_off_the_rack_400w.webp 400w,../images/classifiers_off_the_rack_350w.webp 350w,../images/classifiers_off_the_rack_300w.webp 300w\" alt=\"off the rack classifiers\" />\n",
    "\n",
    "We have written Naive Bayes Classifiers from scratch in our previous chapter of our tutorial. \n",
    "In this part of the tutorial on Machine Learning with Python, we want to show you how to use ready-made classifiers. The module Scikit provides naive Bayes classifiers \"off the rack\".\n",
    "\n",
    "\n",
    "\n",
    "Our first example uses the \"iris dataset\" contained in the model to train and test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       0.94      0.94      0.94        50\n",
      "          2       0.94      0.94      0.94        50\n",
      "\n",
      "avg / total       0.96      0.96      0.96       150\n",
      "\n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our person data from the previous chapter of our tutorial to train another classifier in the next example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((184.0, 73.0), 'male'), ((149.0, 52.0), 'female'), ((174.0, 63.0), 'female'), ((175.0, 67.0), 'male'), ((183.0, 81.0), 'female'), ((187.0, 60.0), 'male'), ((192.0, 96.0), 'male'), ((204.0, 91.0), 'male'), ((180.0, 66.0), 'male'), ((184.0, 52.0), 'male'), ((174.0, 53.0), 'male'), ((177.0, 91.0), 'male'), ((138.0, 37.0), 'female'), ((200.0, 82.0), 'male'), ((193.0, 79.0), 'male'), ((189.0, 79.0), 'male'), ((145.0, 59.0), 'female'), ((188.0, 53.0), 'male'), ((187.0, 81.0), 'male'), ((187.0, 99.0), 'male'), ((190.0, 81.0), 'male'), ((161.0, 48.0), 'female'), ((179.0, 75.0), 'female'), ((180.0, 67.0), 'male'), ((155.0, 48.0), 'male'), ((201.0, 122.0), 'male'), ((162.0, 62.0), 'female'), ((148.0, 49.0), 'female'), ((171.0, 50.0), 'male'), ((196.0, 86.0), 'female'), ((163.0, 46.0), 'female'), ((159.0, 37.0), 'female'), ((163.0, 53.0), 'male'), ((150.0, 39.0), 'female'), ((170.0, 56.0), 'female'), ((191.0, 55.0), 'male'), ((175.0, 37.0), 'male'), ((169.0, 78.0), 'female'), ((167.0, 59.0), 'female'), ((170.0, 78.0), 'male'), ((178.0, 79.0), 'male'), ((168.0, 71.0), 'female'), ((170.0, 37.0), 'female'), ((167.0, 58.0), 'female'), ((152.0, 43.0), 'female'), ((191.0, 81.0), 'male'), ((155.0, 48.0), 'female'), ((176.0, 61.0), 'male'), ((151.0, 41.0), 'female'), ((166.0, 59.0), 'female'), ((168.0, 46.0), 'male'), ((165.0, 65.0), 'female'), ((169.0, 67.0), 'male'), ((158.0, 43.0), 'female'), ((173.0, 61.0), 'male'), ((180.0, 74.0), 'male'), ((212.0, 59.0), 'male'), ((152.0, 62.0), 'female'), ((189.0, 67.0), 'male'), ((159.0, 56.0), 'female'), ((163.0, 58.0), 'female'), ((174.0, 45.0), 'female'), ((174.0, 69.0), 'male'), ((167.0, 47.0), 'male'), ((131.0, 37.0), 'female'), ((154.0, 74.0), 'female'), ((159.0, 59.0), 'female'), ((159.0, 58.0), 'female'), ((177.0, 83.0), 'female'), ((193.0, 96.0), 'male'), ((180.0, 83.0), 'female'), ((164.0, 54.0), 'male'), ((164.0, 64.0), 'female'), ((171.0, 52.0), 'male'), ((163.0, 41.0), 'female'), ((165.0, 30.0), 'male'), ((161.0, 61.0), 'female'), ((198.0, 75.0), 'male'), ((183.0, 70.0), 'female'), ((185.0, 71.0), 'male'), ((175.0, 58.0), 'male'), ((195.0, 89.0), 'male'), ((170.0, 66.0), 'female'), ((167.0, 61.0), 'female'), ((166.0, 65.0), 'female'), ((180.0, 88.0), 'female'), ((164.0, 55.0), 'male'), ((161.0, 53.0), 'female'), ((187.0, 76.0), 'male'), ((170.0, 63.0), 'female'), ((192.0, 101.0), 'male'), ((175.0, 56.0), 'male'), ((190.0, 100.0), 'male'), ((164.0, 63.0), 'male'), ((172.0, 61.0), 'female'), ((168.0, 69.0), 'female'), ((156.0, 51.0), 'female'), ((167.0, 40.0), 'female'), ((161.0, 18.0), 'male'), ((167.0, 56.0), 'female')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prepare_person_dataset(fname):\n",
    "    genders = [\"male\", \"female\"]\n",
    "    persons = []\n",
    "    with open(fname) as fh:\n",
    "        for line in fh:\n",
    "            persons.append(line.strip().split())\n",
    "\n",
    "    firstnames = []\n",
    "    dataset = []  # weight and height\n",
    "\n",
    "\n",
    "    for person in persons:\n",
    "        firstnames.append( (person[0], person[4]) )\n",
    "        height_weight = (float(person[2]), float(person[3]))\n",
    "        dataset.append( (height_weight, person[4]))\n",
    "    return dataset\n",
    "\n",
    "learnset = prepare_person_dataset(\"data/person_data.txt\")\n",
    "testset = prepare_person_dataset(\"data/person_data_testset.txt\")\n",
    "print(learnset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "['female' 'male' 'male' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'male' 'female' 'male'\n",
      " 'female' 'female' 'female' 'male' 'female' 'female' 'male' 'male' 'female'\n",
      " 'female' 'male' 'male' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'female' 'male' 'male' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'female' 'female' 'male' 'female' 'female' 'male'\n",
      " 'female' 'female' 'female' 'female' 'male' 'female' 'female' 'female'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'male' 'female'\n",
      " 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'female' 'male']\n",
      "['female' 'male' 'male' 'female' 'female' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'female' 'female' 'male' 'male' 'female' 'male'\n",
      " 'female' 'male' 'female' 'male' 'male' 'male' 'male' 'female' 'female'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'male' 'female' 'male' 'female' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'female' 'male' 'female' 'male' 'female' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'male' 'female' 'male' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'female'\n",
      " 'female']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.68      0.80      0.73        50\n",
      "       male       0.76      0.62      0.68        50\n",
      "\n",
      "avg / total       0.72      0.71      0.71       100\n",
      "\n",
      "[[40 10]\n",
      " [19 31]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "#print(dataset.data, dataset.target)\n",
    "w, l = zip(*learnset)\n",
    "w = np.array(w)\n",
    "l = np.array(l)\n",
    "\n",
    "\n",
    "model.fit(w, l)\n",
    "print(model)\n",
    "\n",
    "w, l = zip(*testset)\n",
    "w = np.array(w)\n",
    "l = np.array(l)\n",
    "predicted = model.predict(w)\n",
    "print(predicted)\n",
    "print(l)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(l, predicted))\n",
    "print(metrics.confusion_matrix(l, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
