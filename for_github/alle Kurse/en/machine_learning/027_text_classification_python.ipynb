{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification in Python\n",
    "\n",
    "### Introduction\n",
    "\n",
    "\n",
    "<img width=\"30%\" class=\"imgright\" src=\"../images/bag_of_words.webp\" alt=\"Bag of Words\" />\n",
    "\n",
    "In the previous chapter, we have deduced the formula for calculating the probability that a document d belongs to a category or class c, denoted as P(c|d).\n",
    "\n",
    "We have transformed the standard formular for P(c|d), as it is used in many treatises<sup>1</sup>, into a numerically stable form.\n",
    "\n",
    "We use a Naive Bayes classifier for our implementation in Python. The formal introduction into the Naive Bayes approach can be found in our previous chapter.\n",
    "\n",
    "Python is ideal for text classification, because of it's strong string class with powerful methods. Furthermore the regular expression module re of Python provides the user with tools, which are way beyond other programming languages.\n",
    "\n",
    "The only downside might be that this Python implementation is not tuned for efficiency. \n",
    "\n",
    "### Python Implementation of Previous Chapter\n",
    "#### Document Representation\n",
    "\n",
    "The document representation, which is based on the bag of word model, is illustrated in the following diagram: \n",
    "\n",
    "<br><br>\n",
    "<img class=\"img\" src=\"../images/document_representation.webp\" srcset=\"../images/document_representation_600w.webp 600w,../images/document_representation_500w.webp 500w,../images/document_representation_400w.webp 400w,../images/document_representation_350w.webp 350w,../images/document_representation_300w.webp 300w\" alt=\"Document Representation\">\n",
    "<br><br>\n",
    "\n",
    "\n",
    "#### Imports Needed\n",
    "\n",
    "Our implementation needs the regular expression module re and the os module: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use in our implementation the function dict_merge_sum from the exercise 1 of our chapter on [dictionaries](python3_dictionaries.php):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 9, 'd': 18, 'b': 5, 'a': 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_merge_sum(d1, d2):\n",
    "    \"\"\" Two dicionaries d1 and d2 with numerical values and\n",
    "    possibly disjoint keys are merged and the values are added if\n",
    "    the exist in both values, otherwise the missing value is taken to\n",
    "    be 0\"\"\"\n",
    "    \n",
    "    return { k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1) | set(d2) }\n",
    "\n",
    "d1 = dict(a=4, b=5, d=8)\n",
    "d2 = dict(a=1, d=10, e=9)\n",
    "\n",
    "dict_merge_sum(d1, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BagOfWordsClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords(object):\n",
    "    \"\"\" Implementing a bag of words, words corresponding with their \n",
    "    frequency of usages in a \"document\" for usage by the \n",
    "    Document class, Category class and the Pool class.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__number_of_words = 0\n",
    "        self.__bag_of_words = {}\n",
    "        \n",
    "        \n",
    "    def __add__(self, other):\n",
    "        \"\"\" Overloading of the \"+\" operator to join two BagOfWords \"\"\"\n",
    "        \n",
    "        erg = BagOfWords() \n",
    "        erg.__bag_of_words = dict_merge_sum(self.__bag_of_words, \n",
    "                                            other.__bag_of_words)\n",
    "        return erg\n",
    "        \n",
    "    def add_word(self,word):\n",
    "        \"\"\" A word is added in the dictionary __bag_of_words\"\"\"\n",
    "        self.__number_of_words += 1\n",
    "        if word in self.__bag_of_words:\n",
    "            self.__bag_of_words[word] += 1\n",
    "        else:\n",
    "            self.__bag_of_words[word] = 1\n",
    "    \n",
    "    def len(self):\n",
    "        \"\"\" Returning the number of different words of an object \"\"\"\n",
    "        return len(self.__bag_of_words)\n",
    "    \n",
    "    def Words(self):\n",
    "        \"\"\" Returning a list of the words contained in the object \"\"\"\n",
    "        return self.__bag_of_words.keys()\n",
    "    \n",
    "        \n",
    "    def BagOfWords(self):\n",
    "        \"\"\" Returning the dictionary, containing the words (keys) with their frequency (values)\"\"\"\n",
    "        return self.__bag_of_words\n",
    "        \n",
    "    def WordFreq(self,word):\n",
    "        \"\"\" Returning the frequency of a word \"\"\"\n",
    "        if word in self.__bag_of_words:\n",
    "            return self.__bag_of_words[word]\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Document class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document(object):\n",
    "    \"\"\" Used both for learning (training) documents and for testing documents. The optional parameter lear\n",
    "    has to be set to True, if a classificator should be trained. If it is a test document learn has to be set to False. \"\"\"\n",
    "    _vocabulary = BagOfWords()\n",
    " \n",
    "    def __init__(self, vocabulary):\n",
    "        self.__name = \"\"\n",
    "        self.__document_class = None\n",
    "        self._words_and_freq = BagOfWords()\n",
    "        Document._vocabulary = vocabulary\n",
    "    \n",
    "    def read_document(self,filename, learn=False):\n",
    "        \"\"\" A document is read. It is assumed that the document is either encoded in utf-8 or in iso-8859... (latin-1).\n",
    "        The words of the document are stored in a Bag of Words, i.e. self._words_and_freq = BagOfWords() \"\"\"\n",
    "        try:\n",
    "            text = open(filename,\"r\", encoding='utf-8').read()\n",
    "        except UnicodeDecodeError:\n",
    "            text = open(filename,\"r\", encoding='latin-1').read()\n",
    "        text = text.lower()\n",
    "        words = re.split(r\"\\W\",text)\n",
    "\n",
    "        self._number_of_words = 0\n",
    "        for word in words:\n",
    "            self._words_and_freq.add_word(word)\n",
    "            if learn:\n",
    "                Document._vocabulary.add_word(word)\n",
    "\n",
    "\n",
    "    def __add__(self,other):\n",
    "        \"\"\" Overloading the \"+\" operator. Adding two documents consists in adding the BagOfWords of the Documents \"\"\"\n",
    "        res = Document(Document._vocabulary)\n",
    "        res._words_and_freq = self._words_and_freq + other._words_and_freq    \n",
    "        return res\n",
    "    \n",
    "    def vocabulary_length(self):\n",
    "        \"\"\" Returning the length of the vocabulary \"\"\"\n",
    "        return len(Document._vocabulary)\n",
    "                \n",
    "    def WordsAndFreq(self):\n",
    "        \"\"\" Returning the dictionary, containing the words (keys) with their frequency (values) as contained\n",
    "        in the BagOfWords attribute of the document\"\"\"\n",
    "        return self._words_and_freq.BagOfWords()\n",
    "        \n",
    "    def Words(self):\n",
    "        \"\"\" Returning the words of the Document object \"\"\"\n",
    "        d =  self._words_and_freq.BagOfWords()\n",
    "        return d.keys()\n",
    "    \n",
    "    def WordFreq(self,word):\n",
    "        \"\"\" Returning the number of times the word \"word\" appeared in the document \"\"\"\n",
    "        bow =  self._words_and_freq.BagOfWords()\n",
    "        if word in bow:\n",
    "            return bow[word]\n",
    "        else:\n",
    "            return 0\n",
    "                \n",
    "    def __and__(self, other):\n",
    "        \"\"\" Intersection of two documents. A list of words occuring in both documents is returned \"\"\"\n",
    "        intersection = []\n",
    "        words1 = self.Words()\n",
    "        for word in other.Words():\n",
    "            if word in words1:\n",
    "                intersection += [word]\n",
    "        return intersection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category / Collections of Documents \n",
    "\n",
    "This is the class consisting of the documents for one category /class. We use the term category instead of \"class\" so that it will not be confused with Python classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category(Document):\n",
    "    def __init__(self, vocabulary):\n",
    "        Document.__init__(self, vocabulary)\n",
    "        self._number_of_docs = 0\n",
    "\n",
    "    def Probability(self,word):\n",
    "        \"\"\" returns the probabilty of the word \"word\" given the class \"self\" \"\"\"\n",
    "        voc_len = Document._vocabulary.len()\n",
    "        SumN = 0\n",
    "        for i in range(voc_len):\n",
    "            SumN = Category._vocabulary.WordFreq(word)\n",
    "        N = self._words_and_freq.WordFreq(word)\n",
    "        erg = 1 + N\n",
    "        erg /= voc_len + SumN\n",
    "        return erg\n",
    "\n",
    "    def __add__(self,other):\n",
    "        \"\"\" Overloading the \"+\" operator. Adding two Category objects consists in adding the \n",
    "        BagOfWords of the Category objects \"\"\"\n",
    "        res = Category(self._vocabulary)\n",
    "        res._words_and_freq = self._words_and_freq + other._words_and_freq \n",
    " \n",
    "        return res\n",
    "\n",
    "    def SetNumberOfDocs(self, number):\n",
    "        self._number_of_docs = number\n",
    "    \n",
    "    def NumberOfDocuments(self):\n",
    "        return self._number_of_docs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Pool class\n",
    "\n",
    "The pool is the class, where the document classes are trained and kept: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool(object):\n",
    "    def __init__(self):\n",
    "        self.__document_classes = {}\n",
    "        self.__vocabulary = BagOfWords()\n",
    "            \n",
    "    def sum_words_in_class(self, dclass):\n",
    "        \"\"\" The number of times all different words of a dclass appear in a class \"\"\"\n",
    "        sum = 0\n",
    "        for word in self.__vocabulary.Words():\n",
    "            WaF = self.__document_classes[dclass].WordsAndFreq()\n",
    "            if word in WaF:\n",
    "                sum +=  WaF[word]\n",
    "        return sum\n",
    "    \n",
    "    def learn(self, directory, dclass_name):\n",
    "        \"\"\" directory is a path, where the files of the class with the name dclass_name can be found \"\"\"\n",
    "        x = Category(self.__vocabulary)\n",
    "        dir = os.listdir(directory)\n",
    "        for file in dir:\n",
    "            d = Document(self.__vocabulary)\n",
    "            #print(directory + \"/\" + file)\n",
    "            d.read_document(directory + \"/\" +  file, learn = True)\n",
    "            x = x + d\n",
    "        self.__document_classes[dclass_name] = x\n",
    "        x.SetNumberOfDocs(len(dir))\n",
    "\n",
    "    \n",
    "    def Probability(self, doc, dclass = \"\"):\n",
    "        \"\"\"Calculates the probability for a class dclass given a document doc\"\"\"\n",
    "        if dclass:\n",
    "            sum_dclass = self.sum_words_in_class(dclass)\n",
    "            prob = 0\n",
    "        \n",
    "            d = Document(self.__vocabulary)\n",
    "            d.read_document(doc)\n",
    "\n",
    "            for j in self.__document_classes:\n",
    "                sum_j = self.sum_words_in_class(j)\n",
    "                prod = 1\n",
    "                for i in d.Words():\n",
    "                    wf_dclass = 1 + self.__document_classes[dclass].WordFreq(i)\n",
    "                    wf = 1 + self.__document_classes[j].WordFreq(i)\n",
    "                    r = wf * sum_dclass / (wf_dclass * sum_j)\n",
    "                    prod *= r\n",
    "                prob += prod * self.__document_classes[j].NumberOfDocuments() / self.__document_classes[dclass].NumberOfDocuments()\n",
    "            if prob != 0:\n",
    "                return 1 / prob\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            prob_list = []\n",
    "            for dclass in self.__document_classes:\n",
    "                prob = self.Probability(doc, dclass)\n",
    "                prob_list.append([dclass,prob])\n",
    "            prob_list.sort(key = lambda x: x[1], reverse = True)\n",
    "            return prob_list\n",
    "\n",
    "    def DocumentIntersectionWithClasses(self, doc_name):\n",
    "        res = [doc_name]\n",
    "        for dc in self.__document_classes:\n",
    "            d = Document(self.__vocabulary)\n",
    "            d.read_document(doc_name, learn=False)\n",
    "            o = self.__document_classes[dc] &  d\n",
    "            intersection_ratio = len(o) / len(d.Words())\n",
    "            res += (dc, intersection_ratio)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Classifier\n",
    "\n",
    "To be able to learn and test a classifier, we offer a [\"Learn and test set to Download\"](learn_and_test.tbz2). The module NaiveBayes consists of the code we have provided so far, but it can be downloaded for convenience as NaiveBayes.py The learn and test sets contain (old) jokes labelled in six categories: \"clinton\", \"lawyer\", \"math\", \"medical\", \"music\", \"sex\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"clinton: clinton13.txt: [['clinton', 0.9999999999994136], ['lawyer', 4.836910173924097e-13], ['medical', 1.0275816932480502e-13], ['sex', 2.259655644772941e-20], ['music', 1.9461534629330693e-23], ['math', 1.555345744116502e-26]]\", \"clinton: clinton53.txt: [['clinton', 1.0], ['medical', 9.188673872554947e-27], ['lawyer', 1.8427106994083583e-27], ['sex', 1.5230675259429155e-27], ['music', 1.1695224390877453e-31], ['math', 1.1684669623309053e-33]]\", \"clinton: clinton43.txt: [['clinton', 0.9999999931196475], ['lawyer', 5.860057747465498e-09], ['medical', 9.607574904397297e-10], ['sex', 5.894524557321511e-11], ['music', 3.7727719397911977e-13], ['math', 2.147560501376133e-13]]\", \"clinton: clinton3.txt: [['clinton', 0.9999999999999962], ['music', 2.2781994419060397e-15], ['medical', 1.1698375401225822e-15], ['lawyer', 4.527194012614925e-16], ['sex', 1.5454131826930606e-17], ['math', 7.079852963638893e-18]]\", \"clinton: clinton33.txt: [['clinton', 0.9999999999990845], ['sex', 4.541025305456911e-13], ['lawyer', 3.126691883689181e-13], ['medical', 1.3677618519146697e-13], ['music', 1.2066374685712134e-14], ['math', 7.905002788169863e-19]]\", \"clinton: clinton23.txt: [['clinton', 0.9999999990044788], ['music', 9.903297627375497e-10], ['lawyer', 4.599127712898122e-12], ['math', 5.204515552253461e-13], ['sex', 6.840062626646056e-14], ['medical', 3.2400016635923044e-15]]\", \"lawyer: lawyer203.txt: [['lawyer', 0.9786187307635054], ['music', 0.009313838824293683], ['clinton', 0.007226994270357742], ['sex', 0.004650195377700058], ['medical', 0.00019018203662436446], ['math', 5.87275188878159e-08]]\", \"lawyer: lawyer233.txt: [['music', 0.7468245708838688], ['lawyer', 0.2505817879364303], ['clinton', 0.0025913149343268467], ['medical', 1.71345437802292e-06], ['sex', 6.081558428153343e-07], ['math', 4.635153054869146e-09]]\", \"lawyer: lawyer273.txt: [['clinton', 1.0], ['lawyer', 3.1987559043152286e-46], ['music', 1.3296257614591338e-54], ['math', 9.431988300101994e-85], ['sex', 3.1890112632916554e-91], ['medical', 1.5171123775659174e-99]]\", \"lawyer: lawyer213.txt: [['lawyer', 0.9915688655897351], ['music', 0.005065592126015617], ['clinton', 0.003206989396712446], ['math', 6.94882106646087e-05], ['medical', 6.923689581139796e-05], ['sex', 1.982778106069595e-05]]\"]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DClasses = [\"clinton\",  \"lawyer\",  \"math\",  \"medical\",  \"music\",  \"sex\"]\n",
    "\n",
    "base = \"data/jokes/learn/\"\n",
    "p = Pool()\n",
    "for dclass in DClasses:\n",
    "    p.learn(base + dclass, dclass)\n",
    "\n",
    "\n",
    "\n",
    "base = \"data/jokes/test/\"\n",
    "results = []\n",
    "for dclass in DClasses:\n",
    "    dir = os.listdir(base + dclass)\n",
    "    for file in dir:\n",
    "        res = p.Probability(base + dclass + \"/\" + file)\n",
    "        results.append(f\"{dclass}: {file}: {str(res)}\")\n",
    "        \n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Footnotes\n",
    "\n",
    "<sup>1</sup> Please see our \"Further Reading\" section of our previous chapter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
